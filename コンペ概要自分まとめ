入力
test.csv形式

出力
sample_submission.csv形式

    ラベルの選択肢は
    True_Correct, True_Neither, True_Misconception
    False_Correct, False_Neither, False_Misconception

    True, False はMC_Answer が正しいかどうか
    Correct, Neither, Misconception は基本的に StudentExplanation から判断されるものと想定されているはず
    False_misconception に追加のラベルを貼る必要がある可能性があるが一旦無視

評価
MAP@3

    式
    average( P(k) )
    P(k) は １つ目で 1, ２つ目で 1/2, ３つ目で 1/3 のはず

使用モデル構成

    Gemma3n
    重すぎてColab A100上でもout of memoryだった
    カスタムモデル定義とPEFT設定まではできた

    Gemma2-2b
    ColabでA100を使えば3時間程度で訓練して保存できた
    一度これを使って提出を試みる

    DeBERTa
    xsmallは比較的簡単にモデル定義から訓練までできた
    しかしkaggleのT4環境だとそれでも時間がかかった

    LoRA
    勉強のためにLoRAをやってみようと思う

特徴量抽出

    ここがこのコンペのほぼ全ての気がするがどういう特徴量をだすのか？

提出形式
    提出がノートブック形式でありruntime制限があるっぽい
    一回簡単なモデルで提出テストした方が良い

    https://www.kaggle.com/docs/notebooks#the-notebooks-environment
    このコンペの説明のサイトのノートブック環境のところには GPU p100 か TPU v3-8 が使用可能とかいてある

    訓練済みのモデルをアップロードすることもできるっぽくてそのやり方なら大きなモデルでも提出できるかもしれない
    実際1bのモデルを提出している人がいる

base-modelの選択
    コラボ環境でもメモリの制約上Gemma3nをつかうことはできなかった
    実際にどこまでのモデルなら訓練を回せるかどうか検証する必要があると思う

    一度bert系をつかって提出テストをしてみようと思う
    その後勉強のために提出できないかもしれないがより大きいモデルで試したい
        その際colab以外のクラウド環境を試す必要があるかもしれない
        これも勉強にもなるのでやった方がいいかも

    保存済みモデルを使用できることからカグルの環境とモデルを訓練する環境をわけることができるので
    今度は訓練環境の選定をする必要がある

    保存済みモデルを使用するやり方だとGemma2-2b-itは訓練して提出まですることができた

Vertex AIの利用
    勉強を兼ねてVertex AIに触ってみようとおもう
    コンペにはつかえないかもしれないが、これに触ることで色々と実践的なAIの開発のことがわかる気がする
    付随してGCP自体のことも少し勉強した

copiがかいたコードの理解
    勉強のためにコードを理解した方がいい
    特にモデルの定義や訓練の部分などは慎重に読むべき
