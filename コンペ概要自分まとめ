入力
test.csv形式

出力
sample_submission.csv形式

    ラベルの選択肢は
    True_Correct, True_Neither, True_Misconception
    False_Correct, False_Neither, False_Misconception

    True, False はMC_Answer が正しいかどうか
    Correct, Neither, Misconception は基本的に StudentExplanation から判断されるものと想定されているはず
    Neitherの判定は怪しいものがある
    False_misconception に追加のラベルを貼る必要がある可能性があるが一旦無視

Misconceptionの問題
    これまで予測する必要性をそもそも感じないがスコアをあげたかったら考慮するべき
    misconceptionだけを学習するモデルをつくり、モデルを２枚かませるのはどうだろうか
    一旦普通にmisconceptionラベルを含めて訓練することにした、モデルを2枚いれるのはコンペの本題からそれる

評価
MAP@3

    式
    average( P(k) )
    P(k) は １つ目で 1, ２つ目で 1/2, ３つ目で 1/3 のはず

使用モデル

    Gemma3n
    重すぎてColab A100上でもout of memoryだった
    カスタムモデル定義とPEFT設定まではできた

    Gemma2-2b
    ColabでA100を使えば3時間程度で訓練して保存できた
    一度これを使って提出を試みる

    DeBERTa
    xsmallは比較的簡単にモデル定義から訓練までできた
    しかしkaggleのT4環境だとそれでも時間がかかった

LoRA
    勉強のためにLoRAをやってみようと思う
    QLoRAという強化版もあるらしい

特徴量抽出

    ここがこのコンペのほぼ全ての気がするがどういう特徴量をだすのか？

    クリスデオットはcorrectかfalseかだけプロンプトの中にいれるだけでdeber-xsmallで0.93のスコアを出している
    おそらくテストに含まれる問題はトレインに含まれているものと同じなのでこれは簡単にできる
    しかし同じxsmallでこれをしなくても0.93のひともいるから誤差かもしれない

    コパイの提案でタスクを明確に指示、全ラベルを提示することにした、プロンプトはすごく長くなった

提出形式
    提出がノートブック形式でありruntime制限があるっぽい
    一回簡単なモデルで提出テストした方が良い

    https://www.kaggle.com/docs/notebooks#the-notebooks-environment
    このコンペの説明のサイトのノートブック環境のところには GPU p100 か TPU v3-8 が使用可能とかいてある

    訓練済みのモデルをアップロードすることもできるっぽくてそのやり方なら大きなモデルでも提出できるかもしれない
    実際1bのモデルを提出している人がいる

    最後に他人がみても分かるように訓練コードやプロンプトとか説明した方がいい

base-modelの選択
    コラボ環境でもメモリの制約上Gemma3nをつかうことはできなかった
    実際にどこまでのモデルなら訓練を回せるかどうか検証する必要があると思う

    一度bert系をつかって提出テストをしてみようと思う
    その後勉強のために提出できないかもしれないがより大きいモデルで試したい
        その際colab以外のクラウド環境を試す必要があるかもしれない
        これも勉強にもなるのでやった方がいいかも

    保存済みモデルを使用できることからカグルの環境とモデルを訓練する環境をわけることができるので
    今度は訓練環境の選定をする必要がある

    保存済みモデルを使用するやり方だとGemma2-2b-itは訓練して提出まですることができた

Vertex AIの利用
    勉強を兼ねてVertex AIに触ってみようとおもう
    コンペにはつかえないかもしれないが、これに触ることで色々と実践的なAIの開発のことがわかる気がする
    付随してGCP自体のことも少し勉強した

copiがかいたコードの理解
    勉強のためにコードを理解した方がいい
    特にモデルの定義や訓練の部分などは慎重に読むべき


result
    Gemma2-2b-noMis
        base Gemma2-2b-it LoRA適用
        訓練時間 3時間弱
        map 0.93 (提出時0.71 noMisだから)

    Gemma2-2b-improved_prompts_QLoRA
        base Gemma2-2b-it QLoRA適用
        プロンプト改良　明確な指示かつ全ラベル提示
        訓練時間 約8時間
        map 0.9411

考察
    他の人の結果からモデルのサイズを大きくしてもあまり結果が変わらないのは
    データの性質上、特にmisconceptionの部分からその程度が限界なのではないか
    なので予測の形式がもう少しよければ、より大きいモデルでより良い精度がでる可能性はあると思います！
