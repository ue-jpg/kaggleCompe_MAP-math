colabã§ãƒ¢ãƒ‡ãƒ«ã‚’è¨“ç·´ã—ã¦ä¿å­˜ã™ã‚‹ãŸã‚ã®ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯ã‚’ä½œæˆã™ã‚‹

C:\Users\mouse\Desktop\P\learnMachineLearning\kaggleã¯ã˜ã‚ã¦ã®ã‚³ãƒ³ãƒš\colabã§è¨“ç·´ã—ã¦ä¿å­˜\Gemma2-2bä»®.ipynb
ã‚’å‚è€ƒã«ã™ã‚‹

ä½¿ç”¨ãƒ¢ãƒ‡ãƒ«
google/gemma-2-2b-it
è¨“ç·´æ™‚LoRAé©ç”¨
åˆ†é¡ã‚¿ã‚¹ã‚¯ç”¨ã®ã‚«ã‚¹ã‚¿ãƒ ãƒ˜ãƒƒãƒ‰ã‚’å®šç¾©
è¨“ç·´æ™‚ã¯GPU A100ã‚’ä½¿ç”¨

ã‚‚ã¨ã®ãƒ¢ãƒ‡ãƒ«ã®å®šç¾©
def load_gemma_model(device):
    """Gemma-2-2b-itãƒ¢ãƒ‡ãƒ«ã¨ãƒˆãƒ¼ã‚¯ãƒŠã‚¤ã‚¶ãƒ¼ã®èª­ã¿è¾¼ã¿"""
    print("\n" + "=" * 60)
    print(f"ğŸ¤– Gemmaãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿: {MODEL_NAME}")
    print("=" * 60)

    try:
        print("ğŸ“ Gemmaãƒˆãƒ¼ã‚¯ãƒŠã‚¤ã‚¶ãƒ¼èª­ã¿è¾¼ã¿ä¸­...")
        tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)

        # ãƒ‘ãƒ‡ã‚£ãƒ³ã‚°ãƒˆãƒ¼ã‚¯ãƒ³ã®è¨­å®šï¼ˆGemmaã®å ´åˆå¿…è¦ï¼‰
        if tokenizer.pad_token is None:
            tokenizer.pad_token = tokenizer.eos_token
            print("ğŸ”§ ãƒ‘ãƒ‡ã‚£ãƒ³ã‚°ãƒˆãƒ¼ã‚¯ãƒ³ã‚’EOSãƒˆãƒ¼ã‚¯ãƒ³ã«è¨­å®š")

        print(f"âœ… ãƒˆãƒ¼ã‚¯ãƒŠã‚¤ã‚¶ãƒ¼èª­ã¿è¾¼ã¿å®Œäº†")
        print(f"ğŸ”– ãƒ‘ãƒ‡ã‚£ãƒ³ã‚°ãƒˆãƒ¼ã‚¯ãƒ³: {tokenizer.pad_token}")
        print(f"ğŸ“ èªå½™ã‚µã‚¤ã‚º: {tokenizer.vocab_size:,}")

        print("\nğŸ§  Gemmaãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿ä¸­...")

        # åˆ†é¡ã‚¿ã‚¹ã‚¯ç”¨ã®è¨­å®š
        config = AutoConfig.from_pretrained(MODEL_NAME)
        config.num_labels = NUM_LABELS
        config.problem_type = "single_label_classification"

        # Gemma-2-2b-itãƒ¢ãƒ‡ãƒ«ã‚’åˆ†é¡ç”¨ã«èª­ã¿è¾¼ã¿
        model = AutoModelForSequenceClassification.from_pretrained(
            MODEL_NAME,
            config=config,
            torch_dtype=torch.float16 if device.type == "cuda" else torch.float32,
            device_map="auto" if device.type == "cuda" else None,
        )

        print(f"âœ… Gemmaãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿å®Œäº†!")

        # ãƒ¢ãƒ‡ãƒ«æƒ…å ±è¡¨ç¤º
        total_params = sum(p.numel() for p in model.parameters())
        trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)

        print(f"ğŸ“Š åˆ†é¡ã‚¯ãƒ©ã‚¹æ•°: {NUM_LABELS}")
        print(f"ğŸ“ˆ ç·ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°: {total_params:,}")
        print(f"ğŸ¯ è¨“ç·´å¯èƒ½ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°: {trainable_params:,}")
        print(f"ğŸ’¡ ãƒ¢ãƒ‡ãƒ«ã‚µã‚¤ã‚º: ~{total_params / 1e9:.2f}B parameters")

        return model, tokenizer

ã‚‚ã¨ã®ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯ã‹ã‚‰
ãƒ¢ãƒ‡ãƒ«ã‚’è¨“ç·´ã—ã¦ä¿å­˜ã®ã¿ã‚’è¡Œã†ã‚ˆã†ã«æ›¸ãæ›ãˆã‚‹
ä¿å­˜ã¯google drive ã¨ãƒ­ãƒ¼ã‚«ãƒ«ã«ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã™ã‚‹
ä¿å­˜ã—ãŸãƒ¢ãƒ‡ãƒ«ã¯ã‚ã¨ã§ã‚«ã‚°ãƒ«ã«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ä½¿ç”¨ã™ã‚‹ãŸã‚ã‚‚ã¨ã‚‚ã¨ã®ãƒ¢ãƒ‡ãƒ«ã®å®šç¾©ã«ã‚ã†ã‚ˆã†ã«ã™ã‚‹