{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f3c6e7fc",
   "metadata": {},
   "source": [
    "# 🎯 MAP Competition: Gemma-2-2b-it Submission Notebook\n",
    "\n",
    "## Overview\n",
    "このノートブックは、事前に訓練・保存されたGemma-2-2b-itモデルを使用して、MAP - Charting Student Math Misunderstandingsコンペティションの提出を行います。\n",
    "\n",
    "### Model Details\n",
    "- **Pre-trained Model**: google/gemma-2-2b-it\n",
    "- **Parameters**: ~2.6B\n",
    "- **Task**: 6-class text classification\n",
    "- **Evaluation Metric**: MAP@3\n",
    "\n",
    "### Target Classes (6分類)\n",
    "- **True_Correct**: 正解で正しい説明\n",
    "- **True_Neither**: 正解だが曖昧な説明\n",
    "- **True_Misconception**: 正解だが誤った概念の説明\n",
    "- **False_Correct**: 不正解だが正しい概念の説明\n",
    "- **False_Neither**: 不正解で曖昧な説明\n",
    "- **False_Misconception**: 不正解で誤った概念の説明\n",
    "\n",
    "### Strategy\n",
    "1. Kaggleにアップロードされた事前訓練済みモデルを読み込み\n",
    "2. テストデータを前処理\n",
    "3. 推論実行でMAP@3形式の予測生成\n",
    "4. submission.csv作成・提出"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a27de544",
   "metadata": {},
   "source": [
    "## 📦 Install Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c331fc4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kaggle環境で必要なライブラリをインストール\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "def install_package(package):\n",
    "    \"\"\"パッケージをインストールする関数\"\"\"\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package])\n",
    "\n",
    "# 必要なライブラリのインストール（Kaggleで通常不足するもの）\n",
    "required_packages = [\n",
    "    \"transformers>=4.35.0\",\n",
    "    \"accelerate>=0.26.0\", \n",
    "    \"sentencepiece>=0.1.99\"\n",
    "]\n",
    "\n",
    "for package in required_packages:\n",
    "    try:\n",
    "        # インポートテストでインストール状況確認\n",
    "        if \"transformers\" in package:\n",
    "            import transformers\n",
    "            print(f\"✅ transformers already installed: {transformers.__version__}\")\n",
    "        elif \"accelerate\" in package:\n",
    "            import accelerate\n",
    "            print(f\"✅ accelerate already installed: {accelerate.__version__}\")\n",
    "        elif \"sentencepiece\" in package:\n",
    "            import sentencepiece\n",
    "            print(f\"✅ sentencepiece already installed: {sentencepiece.__version__}\")\n",
    "    except ImportError:\n",
    "        print(f\"📦 Installing {package}...\")\n",
    "        install_package(package)\n",
    "\n",
    "print(\"🎉 All required libraries are ready!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a165f27d",
   "metadata": {},
   "source": [
    "## 📚 Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "997bfcf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 基本ライブラリ\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "import time\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "\n",
    "# 機械学習ライブラリ\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# Transformersライブラリ\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSequenceClassification,\n",
    "    DataCollatorWithPadding,\n",
    ")\n",
    "\n",
    "# 警告を非表示\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# デバッグ情報表示\n",
    "print(\"🔧 Environment Information:\")\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA version: {torch.version.cuda}\")\n",
    "    print(f\"GPU device: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"GPU memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    print(\"Running on CPU\")\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "# Kaggleのデータパス設定\n",
    "KAGGLE_INPUT_PATH = \"/kaggle/input\"\n",
    "if os.path.exists(KAGGLE_INPUT_PATH):\n",
    "    print(f\"📁 Kaggle environment detected: {KAGGLE_INPUT_PATH}\")\n",
    "    # コンペティションデータパス\n",
    "    COMP_DATA_PATH = \"/kaggle/input/map-charting-student-math-misunderstandings\"\n",
    "    # アップロードしたモデルのパス（実際のデータセット名に変更してください）\n",
    "    MODEL_DATA_PATH = \"/kaggle/input/gemma-2-2b-math-misconception-model\"\n",
    "    print(f\"🎯 Competition data path: {COMP_DATA_PATH}\")\n",
    "    print(f\"🤖 Model data path: {MODEL_DATA_PATH}\")\n",
    "else:\n",
    "    print(\"📁 Local environment detected\")\n",
    "    COMP_DATA_PATH = \"./map_data\"\n",
    "    MODEL_DATA_PATH = \"./saved_models/gemma-2-2b-math-misconception\"\n",
    "\n",
    "print(\"✅ All libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10c08eb0",
   "metadata": {},
   "source": [
    "## 🔧 Define Dataset Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a76cded",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MathMisconceptionDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Math Misconception Dataset for PyTorch\n",
    "    推論専用のデータセット\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, texts, tokenizer, max_length=512):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            texts (list): テキストデータのリスト\n",
    "            tokenizer: Gemmaトークナイザー\n",
    "            max_length (int): 最大トークン長\n",
    "        \"\"\"\n",
    "        self.texts = texts\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = str(self.texts[idx])\n",
    "\n",
    "        # Gemmaトークナイザーでテキストをエンコード\n",
    "        encoding = self.tokenizer(\n",
    "            text,\n",
    "            truncation=True,\n",
    "            padding=\"max_length\",\n",
    "            max_length=self.max_length,\n",
    "            return_tensors=\"pt\",\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            \"input_ids\": encoding[\"input_ids\"].flatten(),\n",
    "            \"attention_mask\": encoding[\"attention_mask\"].flatten(),\n",
    "        }\n",
    "\n",
    "print(\"✅ MathMisconceptionDataset class defined successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddd7223a",
   "metadata": {},
   "source": [
    "## 🤖 Load Pre-trained Gemma Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9979e124",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pretrained_gemma_model():\n",
    "    \"\"\"事前訓練済みGemmaモデルの読み込み\"\"\"\n",
    "    print(\"=\" * 60)\n",
    "    print(\"🤖 事前訓練済みGemmaモデル読み込み\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    try:\n",
    "        # モデルパス確認\n",
    "        print(f\"📁 モデルパス: {MODEL_DATA_PATH}\")\n",
    "        \n",
    "        if not os.path.exists(MODEL_DATA_PATH):\n",
    "            print(f\"❌ モデルパスが存在しません: {MODEL_DATA_PATH}\")\n",
    "            print(\"💡 Kaggle環境では正しいデータセット名を確認してください\")\n",
    "            return None, None, None\n",
    "        \n",
    "        # ラベルマッピングの読み込み\n",
    "        label_file = os.path.join(MODEL_DATA_PATH, \"label_mapping.json\")\n",
    "        print(f\"📋 ラベルマッピング読み込み: {label_file}\")\n",
    "        \n",
    "        with open(label_file, \"r\", encoding=\"utf-8\") as f:\n",
    "            label_mapping = json.load(f)\n",
    "        \n",
    "        print(\"✅ ラベルマッピング読み込み成功\")\n",
    "        for idx, label in label_mapping.items():\n",
    "            print(f\"   {idx}: {label}\")\n",
    "        \n",
    "        # トークナイザーの読み込み\n",
    "        print(\"\\n📝 Gemmaトークナイザー読み込み中...\")\n",
    "        tokenizer = AutoTokenizer.from_pretrained(MODEL_DATA_PATH)\n",
    "        print(f\"✅ トークナイザー読み込み成功\")\n",
    "        print(f\"🔖 パディングトークン: {tokenizer.pad_token}\")\n",
    "        print(f\"📏 語彙サイズ: {tokenizer.vocab_size:,}\")\n",
    "        \n",
    "        # モデルの読み込み\n",
    "        print(\"\\n🧠 Gemmaモデル読み込み中...\")\n",
    "        model = AutoModelForSequenceClassification.from_pretrained(\n",
    "            MODEL_DATA_PATH,\n",
    "            torch_dtype=torch.float16 if device.type == \"cuda\" else torch.float32,\n",
    "            device_map=\"auto\" if device.type == \"cuda\" else None,\n",
    "        )\n",
    "        \n",
    "        # デバイスに移動（必要に応じて）\n",
    "        if device.type == \"cpu\":\n",
    "            model = model.to(device)\n",
    "        \n",
    "        print(f\"✅ Gemmaモデル読み込み完了!\")\n",
    "        \n",
    "        # モデル情報表示\n",
    "        total_params = sum(p.numel() for p in model.parameters())\n",
    "        print(f\"📊 分類クラス数: {model.config.num_labels}\")\n",
    "        print(f\"📈 総パラメータ数: {total_params:,}\")\n",
    "        print(f\"💡 モデルサイズ: ~{total_params / 1e9:.2f}B parameters\")\n",
    "        \n",
    "        # 推論モードに設定\n",
    "        model.eval()\n",
    "        \n",
    "        return model, tokenizer, label_mapping\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"❌ モデル読み込みエラー: {e}\")\n",
    "        print(\"\\n🔧 トラブルシューティング:\")\n",
    "        print(\"1. Kaggleでモデルデータセットが正しくアップロードされているか確認\")\n",
    "        print(\"2. MODEL_DATA_PATHが正しいデータセット名を指しているか確認\")\n",
    "        print(\"3. 必要なファイルが全て含まれているか確認\")\n",
    "        raise e\n",
    "\n",
    "# モデル読み込み実行\n",
    "model, tokenizer, label_mapping = load_pretrained_gemma_model()\n",
    "print(\"\\n🎉 事前訓練済みモデル準備完了!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0449de47",
   "metadata": {},
   "source": [
    "## 📊 Load and Prepare Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cf08611",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_prepare_test_data():\n",
    "    \"\"\"テストデータの読み込みと前処理\"\"\"\n",
    "    print(\"=\" * 60)\n",
    "    print(\"📊 テストデータ読み込みと前処理\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    try:\n",
    "        # テストデータの読み込み\n",
    "        test_path = os.path.join(COMP_DATA_PATH, \"test.csv\")\n",
    "        print(f\"📁 テストデータパス: {test_path}\")\n",
    "        \n",
    "        if not os.path.exists(test_path):\n",
    "            print(f\"❌ テストデータが見つかりません: {test_path}\")\n",
    "            return None\n",
    "        \n",
    "        test_df = pd.read_csv(test_path)\n",
    "        print(f\"✅ テストデータ読み込み成功!\")\n",
    "        print(f\"📈 テストデータ形状: {test_df.shape}\")\n",
    "        \n",
    "        # データ確認\n",
    "        print(\"\\n📋 テストデータの列:\")\n",
    "        print(test_df.columns.tolist())\n",
    "        \n",
    "        print(\"\\n📋 データサンプル:\")\n",
    "        print(test_df.head(3))\n",
    "        \n",
    "        # 強化されたテキスト特徴量の作成\n",
    "        def create_enhanced_text(row):\n",
    "            \"\"\"Question + MC_Answer + Explanation を結合した強化テキスト\"\"\"\n",
    "            question = str(row.get(\"QuestionText\", \"\")) if pd.notna(row.get(\"QuestionText\")) else \"\"\n",
    "            mc_answer = str(row.get(\"MC_Answer\", \"\")) if pd.notna(row.get(\"MC_Answer\")) else \"\"\n",
    "            explanation = str(row.get(\"StudentExplanation\", \"\")) if pd.notna(row.get(\"StudentExplanation\")) else \"\"\n",
    "            \n",
    "            # Gemma用の構造化テキスト\n",
    "            enhanced_text = f\"Question: {question} Selected Answer: {mc_answer} Explanation: {explanation}\"\n",
    "            return enhanced_text\n",
    "\n",
    "        print(\"\\n🔧 強化テキスト特徴量作成中...\")\n",
    "        test_df[\"enhanced_text\"] = test_df.apply(create_enhanced_text, axis=1)\n",
    "        \n",
    "        # テキスト長の統計\n",
    "        text_lengths = test_df[\"enhanced_text\"].str.len()\n",
    "        print(f\"\\n📊 テキスト長統計:\")\n",
    "        print(f\"   平均: {text_lengths.mean():.0f} 文字\")\n",
    "        print(f\"   最小: {text_lengths.min()} 文字\")\n",
    "        print(f\"   最大: {text_lengths.max()} 文字\")\n",
    "        print(f\"   中央値: {text_lengths.median():.0f} 文字\")\n",
    "        \n",
    "        # サンプルテキストの表示\n",
    "        print(f\"\\n📝 強化テキストサンプル:\")\n",
    "        sample_text = test_df[\"enhanced_text\"].iloc[0]\n",
    "        print(f\"Length: {len(sample_text)} characters\")\n",
    "        print(f\"Sample: {sample_text[:300]}...\")\n",
    "        \n",
    "        return test_df\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"❌ テストデータ読み込みエラー: {e}\")\n",
    "        return None\n",
    "\n",
    "# テストデータ読み込み実行\n",
    "test_df = load_and_prepare_test_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "814efd5e",
   "metadata": {},
   "source": [
    "## 🔮 Generate Predictions for Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01f83497",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_test_predictions(model, tokenizer, test_df, label_mapping, batch_size=8):\n",
    "    \"\"\"テストセットに対する予測生成（MAP@3形式）\"\"\"\n",
    "    print(\"=\" * 60)\n",
    "    print(\"🔮 テストセット予測生成（MAP@3）\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    if test_df is None or len(test_df) == 0:\n",
    "        print(\"❌ テストデータが利用できません\")\n",
    "        return None\n",
    "    \n",
    "    print(f\"📊 テストデータ: {len(test_df):,}件\")\n",
    "    print(f\"🔧 バッチサイズ: {batch_size}\")\n",
    "    \n",
    "    # テストデータの前処理\n",
    "    test_texts = test_df[\"enhanced_text\"].tolist()\n",
    "    \n",
    "    # テストデータセット作成\n",
    "    print(\"🔧 テストデータセット作成中...\")\n",
    "    test_dataset = MathMisconceptionDataset(\n",
    "        test_texts, tokenizer, max_length=512\n",
    "    )\n",
    "    \n",
    "    # データローダー作成\n",
    "    test_dataloader = DataLoader(\n",
    "        test_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        collate_fn=DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "    )\n",
    "    \n",
    "    print(f\"✅ テストデータローダー作成: {len(test_dataloader)}バッチ\")\n",
    "    \n",
    "    # 予測実行\n",
    "    print(\"🔮 予測実行中...\")\n",
    "    all_predictions = []\n",
    "    \n",
    "    try:\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for batch_idx, batch in enumerate(test_dataloader):\n",
    "                # バッチをデバイスに移動\n",
    "                batch = {k: v.to(device) for k, v in batch.items()}\n",
    "                \n",
    "                # 推論実行\n",
    "                outputs = model(**batch)\n",
    "                predictions = outputs.logits\n",
    "                \n",
    "                # CPU に移動してリストに追加\n",
    "                batch_predictions = predictions.cpu().numpy()\n",
    "                all_predictions.append(batch_predictions)\n",
    "                \n",
    "                # 進捗表示\n",
    "                if (batch_idx + 1) % 10 == 0 or (batch_idx + 1) == len(test_dataloader):\n",
    "                    processed = min((batch_idx + 1) * batch_size, len(test_df))\n",
    "                    print(f\"   進捗: {processed:,}/{len(test_df):,} ({processed/len(test_df)*100:.1f}%)\")\n",
    "        \n",
    "        print(\"✅ 予測完了!\")\n",
    "        \n",
    "        # 予測結果を結合\n",
    "        all_predictions = np.vstack(all_predictions)\n",
    "        print(f\"📊 予測結果形状: {all_predictions.shape}\")\n",
    "        \n",
    "        # 確率に変換\n",
    "        probs = torch.softmax(torch.tensor(all_predictions), dim=-1).numpy()\n",
    "        \n",
    "        # 各サンプルで上位3つの予測を取得\n",
    "        print(\"🎯 TOP-3予測抽出中...\")\n",
    "        submission_predictions = []\n",
    "        \n",
    "        # ラベルマッピングの逆変換用\n",
    "        idx_to_label = {int(k): v for k, v in label_mapping.items()}\n",
    "        \n",
    "        for i, prob in enumerate(probs):\n",
    "            # 確率の高い順に上位3つのインデックスを取得\n",
    "            top3_indices = np.argsort(prob)[::-1][:3]\n",
    "            \n",
    "            # インデックスを実際のラベル名に変換\n",
    "            top3_labels = [idx_to_label[idx] for idx in top3_indices]\n",
    "            \n",
    "            # スペース区切りで結合（コンペ要求形式）\n",
    "            prediction_string = \" \".join(top3_labels)\n",
    "            submission_predictions.append(prediction_string)\n",
    "            \n",
    "            # 進捗表示（最初の5件）\n",
    "            if i < 5:\n",
    "                top3_probs = [prob[idx] for idx in top3_indices]\n",
    "                print(f\"  サンプル {i+1}: {prediction_string}\")\n",
    "                print(f\"    確率: {[f'{p:.3f}' for p in top3_probs]}\")\n",
    "        \n",
    "        print(f\"✅ TOP-3予測抽出完了: {len(submission_predictions)}件\")\n",
    "        \n",
    "        # 予測の統計情報\n",
    "        all_pred_labels = \" \".join(submission_predictions).split()\n",
    "        from collections import Counter\n",
    "        pred_counts = Counter(all_pred_labels)\n",
    "        \n",
    "        print(f\"\\n📈 予測統計:\")\n",
    "        print(f\"  予測に使用されたカテゴリ数: {len(pred_counts)}\")\n",
    "        for category, count in pred_counts.most_common():\n",
    "            percentage = count / (len(submission_predictions) * 3) * 100\n",
    "            print(f\"    {category}: {count}回 ({percentage:.1f}%)\")\n",
    "        \n",
    "        return submission_predictions\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"❌ 予測実行中にエラー: {e}\")\n",
    "        if torch.cuda.is_available():\n",
    "            print(f\"🖥️ 現在のGPUメモリ使用量: {torch.cuda.memory_allocated() / 1e6:.1f} MB\")\n",
    "        raise e\n",
    "\n",
    "# 予測実行\n",
    "if model is not None and tokenizer is not None and test_df is not None:\n",
    "    print(\"🔮 テストセット予測を開始します...\")\n",
    "    # バッチサイズを環境に応じて調整\n",
    "    batch_size = 4 if device.type == \"cpu\" else 8\n",
    "    test_predictions = generate_test_predictions(model, tokenizer, test_df, label_mapping, batch_size)\n",
    "    print(\"🎉 テスト予測完了!\")\n",
    "else:\n",
    "    print(\"❌ 必要なコンポーネントが準備されていません\")\n",
    "    test_predictions = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09ccd930",
   "metadata": {},
   "source": [
    "## 📤 Create Submission File\n",
    "\n",
    "最終ステップとして、Kaggleコンペティションに提出するためのCSVファイルを作成します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a5cb096",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_submission_file(test_df, predictions, output_path=\"submission.csv\"):\n",
    "    \"\"\"提出用CSVファイルの作成\"\"\"\n",
    "    print(\"=\" * 60)\n",
    "    print(\"📤 提出ファイル作成\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    if test_df is None or predictions is None:\n",
    "        print(\"❌ テストデータまたは予測結果がありません\")\n",
    "        return None\n",
    "    \n",
    "    print(f\"📊 提出データ: {len(predictions):,}件\")\n",
    "    \n",
    "    # 提出用データフレーム作成\n",
    "    # test_dfのインデックスまたは適切なID列を使用\n",
    "    if 'QuestionId_Answer' in test_df.columns:\n",
    "        submission_df = pd.DataFrame({\n",
    "            'QuestionId_Answer': test_df['QuestionId_Answer'],\n",
    "            'Correct': predictions\n",
    "        })\n",
    "    else:\n",
    "        # ID列がない場合はインデックスを使用\n",
    "        submission_df = pd.DataFrame({\n",
    "            'QuestionId_Answer': test_df.index,\n",
    "            'Correct': predictions\n",
    "        })\n",
    "    \n",
    "    print(f\"✅ 提出データフレーム作成完了: {submission_df.shape}\")\n",
    "    print(f\"📝 列: {list(submission_df.columns)}\")\n",
    "    \n",
    "    # サンプル表示\n",
    "    print(f\"\\n📋 提出データサンプル:\")\n",
    "    print(submission_df.head(10).to_string(index=False))\n",
    "    \n",
    "    # ファイル保存\n",
    "    try:\n",
    "        submission_df.to_csv(output_path, index=False)\n",
    "        print(f\"\\n💾 提出ファイル保存完了: {output_path}\")\n",
    "        \n",
    "        # ファイルサイズ確認\n",
    "        file_size = os.path.getsize(output_path)\n",
    "        print(f\"📏 ファイルサイズ: {file_size:,} bytes ({file_size/1024:.1f} KB)\")\n",
    "        \n",
    "        # 形式確認\n",
    "        check_df = pd.read_csv(output_path)\n",
    "        print(f\"✅ 提出ファイル検証: {check_df.shape}\")\n",
    "        required_cols = ['QuestionId_Answer', 'Correct']\n",
    "        cols_present = all(col in check_df.columns for col in required_cols)\n",
    "        print(f\"   必要列存在確認: {cols_present}\")\n",
    "        \n",
    "        # 予測形式チェック\n",
    "        sample_predictions = check_df['Correct'].head(5).tolist()\n",
    "        print(f\"🔍 予測形式サンプル:\")\n",
    "        for i, pred in enumerate(sample_predictions):\n",
    "            pred_parts = pred.split()\n",
    "            print(f\"   {i+1}: {pred} (要素数: {len(pred_parts)})\")\n",
    "            \n",
    "        print(f\"\\n📊 提出ファイル最終確認:\")\n",
    "        print(f\"   ✅ 形式: MAP@3（各行に3つの予測をスペース区切り）\")\n",
    "        print(f\"   ✅ 件数: {len(check_df):,}件\")\n",
    "        print(f\"   ✅ 列名: {list(check_df.columns)}\")\n",
    "        \n",
    "        return submission_df\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"❌ ファイル保存エラー: {e}\")\n",
    "        return None\n",
    "\n",
    "# 提出ファイルの作成\n",
    "if test_predictions is not None and test_df is not None:\n",
    "    print(\"📤 提出ファイルを作成します...\")\n",
    "    submission_df = create_submission_file(test_df, test_predictions, \"Gemma_2b_submission.csv\")\n",
    "    \n",
    "    if submission_df is not None:\n",
    "        print(\"🎉 提出ファイル作成完了!\")\n",
    "        print(f\"📋 最終確認:\")\n",
    "        print(f\"   ファイル名: Gemma_2b_submission.csv\")\n",
    "        print(f\"   データ件数: {len(submission_df):,}\")\n",
    "        print(f\"   予測形式: MAP@3 (各行に3つの予測をスペース区切り)\")\n",
    "        print(\"\\n🏆 Kaggleコンペティションに提出準備完了!\")\n",
    "        \n",
    "        # 最終チェック用統計\n",
    "        print(f\"\\n📈 提出ファイル統計:\")\n",
    "        all_pred_in_submission = \" \".join(submission_df['Correct']).split()\n",
    "        unique_preds = set(all_pred_in_submission)\n",
    "        print(f\"   使用されたユニークなラベル数: {len(unique_preds)}\")\n",
    "        print(f\"   ラベル一覧: {sorted(unique_preds)}\")\n",
    "    else:\n",
    "        print(\"❌ 提出ファイル作成に失敗しました\")\n",
    "else:\n",
    "    print(\"❌ 必要なデータが準備されていません。前のセルを実行してください。\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8c27647",
   "metadata": {},
   "source": [
    "## 🎯 Summary & Performance Notes\n",
    "\n",
    "### 📊 実行結果サマリー\n",
    "このノートブックでは以下を実装しました：\n",
    "\n",
    "1. **🤖 事前訓練済みモデル読み込み**: KaggleにアップロードされたGemma-2-2b-itモデル\n",
    "2. **📊 テストデータ処理**: math misconceptionコンペティションのtest.csv\n",
    "3. **🔮 効率的な推論**: バッチ処理による高速予測\n",
    "4. **📈 MAP@3形式出力**: TOP-3予測の生成\n",
    "5. **📤 提出準備**: Kaggle形式のsubmission.csv作成\n",
    "\n",
    "### 🚀 使用技術\n",
    "- **モデル**: `google/gemma-2-2b-it` (~2.6B parameters)\n",
    "- **フレームワーク**: PyTorch + Transformers\n",
    "- **推論**: 事前訓練済みモデル使用（追加訓練なし）\n",
    "- **評価**: MAP@3 (Mean Average Precision at 3)\n",
    "\n",
    "### ⚡ パフォーマンス最適化\n",
    "- バッチ処理による効率的な推論\n",
    "- 適応的バッチサイズ（CPU: 4, GPU: 8）\n",
    "- FP16使用（GPU環境）\n",
    "- メモリ効率的なデータローダー\n",
    "\n",
    "### 📝 使用方法\n",
    "1. Kaggleで事前訓練済みモデルをデータセットとしてアップロード\n",
    "2. MODEL_DATA_PATHを正しいデータセット名に変更\n",
    "3. 全セルを順番に実行\n",
    "4. `Gemma_2b_submission.csv`が生成される\n",
    "5. KaggleコンペティションにCSVファイルを提出\n",
    "\n",
    "### 🔧 トラブルシューティング\n",
    "- **メモリ不足**: バッチサイズを下げる\n",
    "- **モデル読み込み失敗**: データセット名とパスを確認\n",
    "- **CUDA OOM**: CPUモードに切り替え\n",
    "\n",
    "**🏆 Good luck with your submission!**"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
