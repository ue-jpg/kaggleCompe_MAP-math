{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2e070df7",
   "metadata": {
    "papermill": {
     "duration": 0.003864,
     "end_time": "2025-07-21T09:42:18.946411",
     "exception": false,
     "start_time": "2025-07-21T09:42:18.942547",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 🎯 MAP Competition: Gemma-2-2b-it Submission Notebook\n",
    "\n",
    "## Overview\n",
    "このノートブックは、事前に訓練・保存されたGemma-2-2b-itモデルを使用して、MAP - Charting Student Math Misunderstandingsコンペティションの提出を行います。\n",
    "\n",
    "### Model Details\n",
    "- **Pre-trained Model**: google/gemma-2-2b-it\n",
    "- **Parameters**: ~2.6B\n",
    "- **Task**: 6-class text classification\n",
    "- **Evaluation Metric**: MAP@3\n",
    "\n",
    "### Target Classes (6分類)\n",
    "- **True_Correct**: 正解で正しい説明\n",
    "- **True_Neither**: 正解だが曖昧な説明\n",
    "- **True_Misconception**: 正解だが誤った概念の説明\n",
    "- **False_Correct**: 不正解だが正しい概念の説明\n",
    "- **False_Neither**: 不正解で曖昧な説明\n",
    "- **False_Misconception**: 不正解で誤った概念の説明\n",
    "\n",
    "### Strategy\n",
    "1. Kaggleにアップロードされた事前訓練済みモデルを読み込み\n",
    "2. テストデータを前処理\n",
    "3. 推論実行でMAP@3形式の予測生成\n",
    "4. submission.csv作成・提出"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f16eb274",
   "metadata": {
    "papermill": {
     "duration": 0.00274,
     "end_time": "2025-07-21T09:42:18.952360",
     "exception": false,
     "start_time": "2025-07-21T09:42:18.949620",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 📦 Install Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "69488c6e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-21T09:42:18.958825Z",
     "iopub.status.busy": "2025-07-21T09:42:18.958583Z",
     "iopub.status.idle": "2025-07-21T09:42:29.743222Z",
     "shell.execute_reply": "2025-07-21T09:42:29.742424Z"
    },
    "papermill": {
     "duration": 10.789453,
     "end_time": "2025-07-21T09:42:29.744542",
     "exception": false,
     "start_time": "2025-07-21T09:42:18.955089",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ transformers already installed: 4.52.4\n",
      "✅ accelerate already installed: 1.8.1\n",
      "✅ sentencepiece already installed: 0.2.0\n",
      "🎉 All required libraries are ready!\n"
     ]
    }
   ],
   "source": [
    "# Kaggle環境で必要なライブラリをインストール\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "def install_package(package):\n",
    "    \"\"\"パッケージをインストールする関数\"\"\"\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package])\n",
    "\n",
    "# 必要なライブラリのインストール（Kaggleで通常不足するもの）\n",
    "required_packages = [\n",
    "    \"transformers>=4.35.0\",\n",
    "    \"accelerate>=0.26.0\", \n",
    "    \"sentencepiece>=0.1.99\"\n",
    "]\n",
    "\n",
    "for package in required_packages:\n",
    "    try:\n",
    "        # インポートテストでインストール状況確認\n",
    "        if \"transformers\" in package:\n",
    "            import transformers\n",
    "            print(f\"✅ transformers already installed: {transformers.__version__}\")\n",
    "        elif \"accelerate\" in package:\n",
    "            import accelerate\n",
    "            print(f\"✅ accelerate already installed: {accelerate.__version__}\")\n",
    "        elif \"sentencepiece\" in package:\n",
    "            import sentencepiece\n",
    "            print(f\"✅ sentencepiece already installed: {sentencepiece.__version__}\")\n",
    "    except ImportError:\n",
    "        print(f\"📦 Installing {package}...\")\n",
    "        install_package(package)\n",
    "\n",
    "print(\"🎉 All required libraries are ready!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7078da9b",
   "metadata": {
    "papermill": {
     "duration": 0.002713,
     "end_time": "2025-07-21T09:42:29.750524",
     "exception": false,
     "start_time": "2025-07-21T09:42:29.747811",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 📚 Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3c4ea7fc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-21T09:42:29.757118Z",
     "iopub.status.busy": "2025-07-21T09:42:29.756789Z",
     "iopub.status.idle": "2025-07-21T09:42:52.985482Z",
     "shell.execute_reply": "2025-07-21T09:42:52.984604Z"
    },
    "papermill": {
     "duration": 23.233486,
     "end_time": "2025-07-21T09:42:52.986793",
     "exception": false,
     "start_time": "2025-07-21T09:42:29.753307",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-21 09:42:37.625936: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1753090957.990726      19 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1753090958.093713      19 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔧 Environment Information:\n",
      "PyTorch version: 2.6.0+cu124\n",
      "CUDA available: True\n",
      "CUDA version: 12.4\n",
      "GPU device: Tesla T4\n",
      "GPU memory: 15.8 GB\n",
      "📁 Kaggle environment detected: /kaggle/input\n",
      "🎯 Competition data path: /kaggle/input/map-charting-student-math-misunderstandings\n",
      "🤖 Model data path: /kaggle/input/test_gemma-2-2b-math-misconception/transformers/default/1/gemma-2-2b-math-misconception\n",
      "✅ All libraries imported successfully!\n"
     ]
    }
   ],
   "source": [
    "# 基本ライブラリ\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "import time\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "\n",
    "# 機械学習ライブラリ\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# Transformersライブラリ\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSequenceClassification,\n",
    "    DataCollatorWithPadding,\n",
    ")\n",
    "\n",
    "# 警告を非表示\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# デバッグ情報表示\n",
    "print(\"🔧 Environment Information:\")\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA version: {torch.version.cuda}\")\n",
    "    print(f\"GPU device: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"GPU memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    print(\"Running on CPU\")\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "# Kaggleのデータパス設定\n",
    "KAGGLE_INPUT_PATH = \"/kaggle/input\"\n",
    "if os.path.exists(KAGGLE_INPUT_PATH):\n",
    "    print(f\"📁 Kaggle environment detected: {KAGGLE_INPUT_PATH}\")\n",
    "    # コンペティションデータパス\n",
    "    COMP_DATA_PATH = \"/kaggle/input/map-charting-student-math-misunderstandings\"\n",
    "    # アップロードしたモデルのパス（実際のデータセット名に変更してください）\n",
    "    MODEL_DATA_PATH = \"/kaggle/input/test_gemma-2-2b-math-misconception/transformers/default/1/gemma-2-2b-math-misconception\"\n",
    "    print(f\"🎯 Competition data path: {COMP_DATA_PATH}\")\n",
    "    print(f\"🤖 Model data path: {MODEL_DATA_PATH}\")\n",
    "else:\n",
    "    print(\"📁 Local environment detected\")\n",
    "    COMP_DATA_PATH = \"./map_data\"\n",
    "    MODEL_DATA_PATH = \"./saved_models/gemma-2-2b-math-misconception\"\n",
    "\n",
    "print(\"✅ All libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0117d81e",
   "metadata": {
    "papermill": {
     "duration": 0.002902,
     "end_time": "2025-07-21T09:42:52.993011",
     "exception": false,
     "start_time": "2025-07-21T09:42:52.990109",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 🔧 Define Dataset Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7cb6105b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-21T09:42:53.000122Z",
     "iopub.status.busy": "2025-07-21T09:42:52.999649Z",
     "iopub.status.idle": "2025-07-21T09:42:53.005650Z",
     "shell.execute_reply": "2025-07-21T09:42:53.004788Z"
    },
    "papermill": {
     "duration": 0.010832,
     "end_time": "2025-07-21T09:42:53.006824",
     "exception": false,
     "start_time": "2025-07-21T09:42:52.995992",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ MathMisconceptionDataset class defined successfully!\n"
     ]
    }
   ],
   "source": [
    "class MathMisconceptionDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Math Misconception Dataset for PyTorch\n",
    "    推論専用のデータセット\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, texts, tokenizer, max_length=512):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            texts (list): テキストデータのリスト\n",
    "            tokenizer: Gemmaトークナイザー\n",
    "            max_length (int): 最大トークン長\n",
    "        \"\"\"\n",
    "        self.texts = texts\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = str(self.texts[idx])\n",
    "\n",
    "        # Gemmaトークナイザーでテキストをエンコード\n",
    "        encoding = self.tokenizer(\n",
    "            text,\n",
    "            truncation=True,\n",
    "            padding=\"max_length\",\n",
    "            max_length=self.max_length,\n",
    "            return_tensors=\"pt\",\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            \"input_ids\": encoding[\"input_ids\"].flatten(),\n",
    "            \"attention_mask\": encoding[\"attention_mask\"].flatten(),\n",
    "        }\n",
    "\n",
    "print(\"✅ MathMisconceptionDataset class defined successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78cf6724",
   "metadata": {
    "papermill": {
     "duration": 0.002896,
     "end_time": "2025-07-21T09:42:53.012727",
     "exception": false,
     "start_time": "2025-07-21T09:42:53.009831",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 🤖 Load Pre-trained Gemma Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ce8575d3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-21T09:42:53.019520Z",
     "iopub.status.busy": "2025-07-21T09:42:53.019277Z",
     "iopub.status.idle": "2025-07-21T09:43:48.688798Z",
     "shell.execute_reply": "2025-07-21T09:43:48.687994Z"
    },
    "papermill": {
     "duration": 55.674434,
     "end_time": "2025-07-21T09:43:48.690133",
     "exception": false,
     "start_time": "2025-07-21T09:42:53.015699",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "🤖 事前訓練済みGemmaモデル読み込み\n",
      "============================================================\n",
      "📁 モデルパス: /kaggle/input/test_gemma-2-2b-math-misconception/transformers/default/1/gemma-2-2b-math-misconception\n",
      "📋 ラベルマッピング読み込み: /kaggle/input/test_gemma-2-2b-math-misconception/transformers/default/1/gemma-2-2b-math-misconception/label_mapping.json\n",
      "✅ ラベルマッピング読み込み成功\n",
      "   0: False_Correct\n",
      "   1: False_Misconception\n",
      "   2: False_Neither\n",
      "   3: True_Correct\n",
      "   4: True_Misconception\n",
      "   5: True_Neither\n",
      "\n",
      "📝 Gemmaトークナイザー読み込み中...\n",
      "✅ トークナイザー読み込み成功\n",
      "🔖 パディングトークン: <pad>\n",
      "📏 語彙サイズ: 256,000\n",
      "\n",
      "🧠 Gemmaモデル読み込み中...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8b2d2e344ae4d82af49f5c7c2d44afd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Gemmaモデル読み込み完了!\n",
      "📊 分類クラス数: 6\n",
      "📈 総パラメータ数: 2,614,355,712\n",
      "💡 モデルサイズ: ~2.61B parameters\n",
      "\n",
      "🎉 事前訓練済みモデル準備完了!\n"
     ]
    }
   ],
   "source": [
    "def load_pretrained_gemma_model():\n",
    "    \"\"\"事前訓練済みGemmaモデルの読み込み\"\"\"\n",
    "    print(\"=\" * 60)\n",
    "    print(\"🤖 事前訓練済みGemmaモデル読み込み\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    try:\n",
    "        # モデルパス確認\n",
    "        print(f\"📁 モデルパス: {MODEL_DATA_PATH}\")\n",
    "        \n",
    "        if not os.path.exists(MODEL_DATA_PATH):\n",
    "            print(f\"❌ モデルパスが存在しません: {MODEL_DATA_PATH}\")\n",
    "            print(\"💡 Kaggle環境では正しいデータセット名を確認してください\")\n",
    "            return None, None, None\n",
    "        \n",
    "        # ラベルマッピングの読み込み\n",
    "        label_file = os.path.join(MODEL_DATA_PATH, \"label_mapping.json\")\n",
    "        print(f\"📋 ラベルマッピング読み込み: {label_file}\")\n",
    "        \n",
    "        with open(label_file, \"r\", encoding=\"utf-8\") as f:\n",
    "            label_mapping = json.load(f)\n",
    "        \n",
    "        print(\"✅ ラベルマッピング読み込み成功\")\n",
    "        for idx, label in label_mapping.items():\n",
    "            print(f\"   {idx}: {label}\")\n",
    "        \n",
    "        # トークナイザーの読み込み\n",
    "        print(\"\\n📝 Gemmaトークナイザー読み込み中...\")\n",
    "        tokenizer = AutoTokenizer.from_pretrained(MODEL_DATA_PATH)\n",
    "        print(f\"✅ トークナイザー読み込み成功\")\n",
    "        print(f\"🔖 パディングトークン: {tokenizer.pad_token}\")\n",
    "        print(f\"📏 語彙サイズ: {tokenizer.vocab_size:,}\")\n",
    "        \n",
    "        # モデルの読み込み\n",
    "        print(\"\\n🧠 Gemmaモデル読み込み中...\")\n",
    "        model = AutoModelForSequenceClassification.from_pretrained(\n",
    "            MODEL_DATA_PATH,\n",
    "            torch_dtype=torch.float16 if device.type == \"cuda\" else torch.float32,\n",
    "            device_map=\"auto\" if device.type == \"cuda\" else None,\n",
    "        )\n",
    "        \n",
    "        # デバイスに移動（必要に応じて）\n",
    "        if device.type == \"cpu\":\n",
    "            model = model.to(device)\n",
    "        \n",
    "        print(f\"✅ Gemmaモデル読み込み完了!\")\n",
    "        \n",
    "        # モデル情報表示\n",
    "        total_params = sum(p.numel() for p in model.parameters())\n",
    "        print(f\"📊 分類クラス数: {model.config.num_labels}\")\n",
    "        print(f\"📈 総パラメータ数: {total_params:,}\")\n",
    "        print(f\"💡 モデルサイズ: ~{total_params / 1e9:.2f}B parameters\")\n",
    "        \n",
    "        # 推論モードに設定\n",
    "        model.eval()\n",
    "        \n",
    "        return model, tokenizer, label_mapping\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"❌ モデル読み込みエラー: {e}\")\n",
    "        print(\"\\n🔧 トラブルシューティング:\")\n",
    "        print(\"1. Kaggleでモデルデータセットが正しくアップロードされているか確認\")\n",
    "        print(\"2. MODEL_DATA_PATHが正しいデータセット名を指しているか確認\")\n",
    "        print(\"3. 必要なファイルが全て含まれているか確認\")\n",
    "        raise e\n",
    "\n",
    "# モデル読み込み実行\n",
    "model, tokenizer, label_mapping = load_pretrained_gemma_model()\n",
    "print(\"\\n🎉 事前訓練済みモデル準備完了!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d062c1c",
   "metadata": {
    "papermill": {
     "duration": 0.003176,
     "end_time": "2025-07-21T09:43:48.696898",
     "exception": false,
     "start_time": "2025-07-21T09:43:48.693722",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 📊 Load and Prepare Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6b985ba4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-21T09:43:48.705643Z",
     "iopub.status.busy": "2025-07-21T09:43:48.705097Z",
     "iopub.status.idle": "2025-07-21T09:43:48.741362Z",
     "shell.execute_reply": "2025-07-21T09:43:48.740393Z"
    },
    "papermill": {
     "duration": 0.042372,
     "end_time": "2025-07-21T09:43:48.742578",
     "exception": false,
     "start_time": "2025-07-21T09:43:48.700206",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "📊 テストデータ読み込みと前処理\n",
      "============================================================\n",
      "📁 テストデータパス: /kaggle/input/map-charting-student-math-misunderstandings/test.csv\n",
      "✅ テストデータ読み込み成功!\n",
      "📈 テストデータ形状: (3, 5)\n",
      "\n",
      "📋 テストデータの列:\n",
      "['row_id', 'QuestionId', 'QuestionText', 'MC_Answer', 'StudentExplanation']\n",
      "\n",
      "📋 データサンプル:\n",
      "   row_id  QuestionId                                       QuestionText  \\\n",
      "0   36696       31772  What fraction of the shape is not shaded? Give...   \n",
      "1   36697       31772  What fraction of the shape is not shaded? Give...   \n",
      "2   36698       32835                      Which number is the greatest?   \n",
      "\n",
      "           MC_Answer                                 StudentExplanation  \n",
      "0  \\( \\frac{1}{3} \\)  I think that 1/3 is the answer, as it's the si...  \n",
      "1  \\( \\frac{3}{6} \\)  i think this answer is because 3 triangles are...  \n",
      "2          \\( 6.2 \\)     because the 2 makes it higher than the others.  \n",
      "\n",
      "🔧 強化テキスト特徴量作成中...\n",
      "\n",
      "📊 テキスト長統計:\n",
      "   平均: 235 文字\n",
      "   最小: 126 文字\n",
      "   最大: 296 文字\n",
      "   中央値: 284 文字\n",
      "\n",
      "📝 強化テキストサンプル:\n",
      "Length: 284 characters\n",
      "Sample: Question: What fraction of the shape is not shaded? Give your answer in its simplest form. [Image: A triangle split into 9 equal smaller triangles. 6 of them are shaded.] Selected Answer: \\( \\frac{1}{3} \\) Explanation: I think that 1/3 is the answer, as it's the simplest form of 3/9....\n"
     ]
    }
   ],
   "source": [
    "def load_and_prepare_test_data():\n",
    "    \"\"\"テストデータの読み込みと前処理\"\"\"\n",
    "    print(\"=\" * 60)\n",
    "    print(\"📊 テストデータ読み込みと前処理\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    try:\n",
    "        # テストデータの読み込み\n",
    "        test_path = os.path.join(COMP_DATA_PATH, \"test.csv\")\n",
    "        print(f\"📁 テストデータパス: {test_path}\")\n",
    "        \n",
    "        if not os.path.exists(test_path):\n",
    "            print(f\"❌ テストデータが見つかりません: {test_path}\")\n",
    "            return None\n",
    "        \n",
    "        test_df = pd.read_csv(test_path)\n",
    "        print(f\"✅ テストデータ読み込み成功!\")\n",
    "        print(f\"📈 テストデータ形状: {test_df.shape}\")\n",
    "        \n",
    "        # データ確認\n",
    "        print(\"\\n📋 テストデータの列:\")\n",
    "        print(test_df.columns.tolist())\n",
    "        \n",
    "        print(\"\\n📋 データサンプル:\")\n",
    "        print(test_df.head(3))\n",
    "        \n",
    "        # 強化されたテキスト特徴量の作成\n",
    "        def create_enhanced_text(row):\n",
    "            \"\"\"Question + MC_Answer + Explanation を結合した強化テキスト\"\"\"\n",
    "            question = str(row.get(\"QuestionText\", \"\")) if pd.notna(row.get(\"QuestionText\")) else \"\"\n",
    "            mc_answer = str(row.get(\"MC_Answer\", \"\")) if pd.notna(row.get(\"MC_Answer\")) else \"\"\n",
    "            explanation = str(row.get(\"StudentExplanation\", \"\")) if pd.notna(row.get(\"StudentExplanation\")) else \"\"\n",
    "            \n",
    "            # Gemma用の構造化テキスト\n",
    "            enhanced_text = f\"Question: {question} Selected Answer: {mc_answer} Explanation: {explanation}\"\n",
    "            return enhanced_text\n",
    "\n",
    "        print(\"\\n🔧 強化テキスト特徴量作成中...\")\n",
    "        test_df[\"enhanced_text\"] = test_df.apply(create_enhanced_text, axis=1)\n",
    "        \n",
    "        # テキスト長の統計\n",
    "        text_lengths = test_df[\"enhanced_text\"].str.len()\n",
    "        print(f\"\\n📊 テキスト長統計:\")\n",
    "        print(f\"   平均: {text_lengths.mean():.0f} 文字\")\n",
    "        print(f\"   最小: {text_lengths.min()} 文字\")\n",
    "        print(f\"   最大: {text_lengths.max()} 文字\")\n",
    "        print(f\"   中央値: {text_lengths.median():.0f} 文字\")\n",
    "        \n",
    "        # サンプルテキストの表示\n",
    "        print(f\"\\n📝 強化テキストサンプル:\")\n",
    "        sample_text = test_df[\"enhanced_text\"].iloc[0]\n",
    "        print(f\"Length: {len(sample_text)} characters\")\n",
    "        print(f\"Sample: {sample_text[:300]}...\")\n",
    "        \n",
    "        return test_df\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"❌ テストデータ読み込みエラー: {e}\")\n",
    "        return None\n",
    "\n",
    "# テストデータ読み込み実行\n",
    "test_df = load_and_prepare_test_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06fc7823",
   "metadata": {
    "papermill": {
     "duration": 0.003145,
     "end_time": "2025-07-21T09:43:48.749140",
     "exception": false,
     "start_time": "2025-07-21T09:43:48.745995",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 🔮 Generate Predictions for Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1df2435d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-21T09:43:48.756510Z",
     "iopub.status.busy": "2025-07-21T09:43:48.756273Z",
     "iopub.status.idle": "2025-07-21T09:43:50.383373Z",
     "shell.execute_reply": "2025-07-21T09:43:50.382342Z"
    },
    "papermill": {
     "duration": 1.632398,
     "end_time": "2025-07-21T09:43:50.384792",
     "exception": false,
     "start_time": "2025-07-21T09:43:48.752394",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔮 テストセット予測を開始します...\n",
      "============================================================\n",
      "🔮 テストセット予測生成（MAP@3）\n",
      "============================================================\n",
      "📊 テストデータ: 3件\n",
      "🔧 バッチサイズ: 8\n",
      "🔧 テストデータセット作成中...\n",
      "✅ テストデータローダー作成: 1バッチ\n",
      "🔮 予測実行中...\n",
      "   進捗: 3/3 (100.0%)\n",
      "✅ 予測完了!\n",
      "📊 予測結果形状: (3, 6)\n",
      "🎯 TOP-3予測抽出中...\n",
      "  サンプル 1: True_Neither True_Misconception False_Correct\n",
      "    確率: ['0.965', '0.027', '0.005']\n",
      "  サンプル 2: True_Neither True_Misconception False_Correct\n",
      "    確率: ['0.937', '0.041', '0.018']\n",
      "  サンプル 3: True_Neither True_Misconception False_Correct\n",
      "    確率: ['0.537', '0.435', '0.016']\n",
      "✅ TOP-3予測抽出完了: 3件\n",
      "\n",
      "📈 予測統計:\n",
      "  予測に使用されたカテゴリ数: 3\n",
      "    True_Neither: 3回 (33.3%)\n",
      "    True_Misconception: 3回 (33.3%)\n",
      "    False_Correct: 3回 (33.3%)\n",
      "🎉 テスト予測完了!\n"
     ]
    }
   ],
   "source": [
    "def generate_test_predictions(model, tokenizer, test_df, label_mapping, batch_size=8):\n",
    "    \"\"\"テストセットに対する予測生成（MAP@3形式）\"\"\"\n",
    "    print(\"=\" * 60)\n",
    "    print(\"🔮 テストセット予測生成（MAP@3）\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    if test_df is None or len(test_df) == 0:\n",
    "        print(\"❌ テストデータが利用できません\")\n",
    "        return None\n",
    "    \n",
    "    print(f\"📊 テストデータ: {len(test_df):,}件\")\n",
    "    print(f\"🔧 バッチサイズ: {batch_size}\")\n",
    "    \n",
    "    # テストデータの前処理\n",
    "    test_texts = test_df[\"enhanced_text\"].tolist()\n",
    "    \n",
    "    # テストデータセット作成\n",
    "    print(\"🔧 テストデータセット作成中...\")\n",
    "    test_dataset = MathMisconceptionDataset(\n",
    "        test_texts, tokenizer, max_length=512\n",
    "    )\n",
    "    \n",
    "    # データローダー作成\n",
    "    test_dataloader = DataLoader(\n",
    "        test_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        collate_fn=DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "    )\n",
    "    \n",
    "    print(f\"✅ テストデータローダー作成: {len(test_dataloader)}バッチ\")\n",
    "    \n",
    "    # 予測実行\n",
    "    print(\"🔮 予測実行中...\")\n",
    "    all_predictions = []\n",
    "    \n",
    "    try:\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for batch_idx, batch in enumerate(test_dataloader):\n",
    "                # バッチをデバイスに移動\n",
    "                batch = {k: v.to(device) for k, v in batch.items()}\n",
    "                \n",
    "                # 推論実行\n",
    "                outputs = model(**batch)\n",
    "                predictions = outputs.logits\n",
    "                \n",
    "                # CPU に移動してリストに追加\n",
    "                batch_predictions = predictions.cpu().numpy()\n",
    "                all_predictions.append(batch_predictions)\n",
    "                \n",
    "                # 進捗表示\n",
    "                if (batch_idx + 1) % 10 == 0 or (batch_idx + 1) == len(test_dataloader):\n",
    "                    processed = min((batch_idx + 1) * batch_size, len(test_df))\n",
    "                    print(f\"   進捗: {processed:,}/{len(test_df):,} ({processed/len(test_df)*100:.1f}%)\")\n",
    "        \n",
    "        print(\"✅ 予測完了!\")\n",
    "        \n",
    "        # 予測結果を結合\n",
    "        all_predictions = np.vstack(all_predictions)\n",
    "        print(f\"📊 予測結果形状: {all_predictions.shape}\")\n",
    "        \n",
    "        # 確率に変換\n",
    "        probs = torch.softmax(torch.tensor(all_predictions), dim=-1).numpy()\n",
    "        \n",
    "        # 各サンプルで上位3つの予測を取得\n",
    "        print(\"🎯 TOP-3予測抽出中...\")\n",
    "        submission_predictions = []\n",
    "        \n",
    "        # ラベルマッピングの逆変換用\n",
    "        idx_to_label = {int(k): v for k, v in label_mapping.items()}\n",
    "        \n",
    "        for i, prob in enumerate(probs):\n",
    "            # 確率の高い順に上位3つのインデックスを取得\n",
    "            top3_indices = np.argsort(prob)[::-1][:3]\n",
    "            \n",
    "            # インデックスを実際のラベル名に変換\n",
    "            top3_labels = [idx_to_label[idx] for idx in top3_indices]\n",
    "            \n",
    "            # スペース区切りで結合（コンペ要求形式）\n",
    "            prediction_string = \" \".join(top3_labels)\n",
    "            submission_predictions.append(prediction_string)\n",
    "            \n",
    "            # 進捗表示（最初の5件）\n",
    "            if i < 5:\n",
    "                top3_probs = [prob[idx] for idx in top3_indices]\n",
    "                print(f\"  サンプル {i+1}: {prediction_string}\")\n",
    "                print(f\"    確率: {[f'{p:.3f}' for p in top3_probs]}\")\n",
    "        \n",
    "        print(f\"✅ TOP-3予測抽出完了: {len(submission_predictions)}件\")\n",
    "        \n",
    "        # 予測の統計情報\n",
    "        all_pred_labels = \" \".join(submission_predictions).split()\n",
    "        from collections import Counter\n",
    "        pred_counts = Counter(all_pred_labels)\n",
    "        \n",
    "        print(f\"\\n📈 予測統計:\")\n",
    "        print(f\"  予測に使用されたカテゴリ数: {len(pred_counts)}\")\n",
    "        for category, count in pred_counts.most_common():\n",
    "            percentage = count / (len(submission_predictions) * 3) * 100\n",
    "            print(f\"    {category}: {count}回 ({percentage:.1f}%)\")\n",
    "        \n",
    "        return submission_predictions\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"❌ 予測実行中にエラー: {e}\")\n",
    "        if torch.cuda.is_available():\n",
    "            print(f\"🖥️ 現在のGPUメモリ使用量: {torch.cuda.memory_allocated() / 1e6:.1f} MB\")\n",
    "        raise e\n",
    "\n",
    "# 予測実行\n",
    "if model is not None and tokenizer is not None and test_df is not None:\n",
    "    print(\"🔮 テストセット予測を開始します...\")\n",
    "    # バッチサイズを環境に応じて調整\n",
    "    batch_size = 4 if device.type == \"cpu\" else 8\n",
    "    test_predictions = generate_test_predictions(model, tokenizer, test_df, label_mapping, batch_size)\n",
    "    print(\"🎉 テスト予測完了!\")\n",
    "else:\n",
    "    print(\"❌ 必要なコンポーネントが準備されていません\")\n",
    "    test_predictions = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b44b843f",
   "metadata": {
    "papermill": {
     "duration": 0.003718,
     "end_time": "2025-07-21T09:43:50.392570",
     "exception": false,
     "start_time": "2025-07-21T09:43:50.388852",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 📤 Create Submission File\n",
    "\n",
    "最終ステップとして、Kaggleコンペティションに提出するためのCSVファイルを作成します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "86c135b0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-21T09:43:50.400844Z",
     "iopub.status.busy": "2025-07-21T09:43:50.400605Z",
     "iopub.status.idle": "2025-07-21T09:43:50.421219Z",
     "shell.execute_reply": "2025-07-21T09:43:50.420450Z"
    },
    "papermill": {
     "duration": 0.02642,
     "end_time": "2025-07-21T09:43:50.422502",
     "exception": false,
     "start_time": "2025-07-21T09:43:50.396082",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📤 提出ファイルを作成します...\n",
      "============================================================\n",
      "📤 提出ファイル作成\n",
      "============================================================\n",
      "📊 提出データ: 3件\n",
      "🔧 Kaggle提出形式に変換中...\n",
      "  サンプル 1: True_Neither:NA True_Misconception:Incomplete False_Correct:NA\n",
      "  サンプル 2: True_Neither:NA True_Misconception:Incomplete False_Correct:NA\n",
      "  サンプル 3: True_Neither:NA True_Misconception:Incomplete False_Correct:NA\n",
      "✅ 提出データフレーム作成完了: (3, 2)\n",
      "📝 列: ['row_id', 'Category:Misconception']\n",
      "\n",
      "📋 提出データサンプル:\n",
      " row_id                                         Category:Misconception\n",
      "  36696 True_Neither:NA True_Misconception:Incomplete False_Correct:NA\n",
      "  36697 True_Neither:NA True_Misconception:Incomplete False_Correct:NA\n",
      "  36698 True_Neither:NA True_Misconception:Incomplete False_Correct:NA\n",
      "\n",
      "💾 提出ファイル保存完了: submission.csv\n",
      "📏 ファイルサイズ: 237 bytes (0.2 KB)\n",
      "✅ 提出ファイル検証: (3, 2)\n",
      "   必要列存在確認: True\n",
      "🔍 予測形式サンプル:\n",
      "   1: True_Neither:NA True_Misconception:Incomplete False_Correct:NA (要素数: 3)\n",
      "   2: True_Neither:NA True_Misconception:Incomplete False_Correct:NA (要素数: 3)\n",
      "   3: True_Neither:NA True_Misconception:Incomplete False_Correct:NA (要素数: 3)\n",
      "\n",
      "📊 提出ファイル最終確認:\n",
      "   ✅ 形式: Kaggle MAP競技形式（row_id, Category:Misconception）\n",
      "   ✅ 件数: 3件\n",
      "   ✅ 列名: ['row_id', 'Category:Misconception']\n",
      "🎉 提出ファイル作成完了!\n",
      "📋 最終確認:\n",
      "   ファイル名: submission.csv\n",
      "   データ件数: 3\n",
      "   予測形式: Kaggle MAP形式 (row_id, Category:Misconception)\n",
      "\n",
      "🏆 Kaggleコンペティションに提出準備完了!\n",
      "\n",
      "📈 提出ファイル統計:\n",
      "   使用されたユニークなラベル数: 3\n",
      "   ラベル一覧: ['False_Correct:NA', 'True_Misconception:Incomplete', 'True_Neither:NA']\n"
     ]
    }
   ],
   "source": [
    "def create_submission_file(test_df, predictions, output_path=\"submission.csv\"):\n",
    "    \"\"\"提出用CSVファイルの作成\"\"\"\n",
    "    print(\"=\" * 60)\n",
    "    print(\"📤 提出ファイル作成\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    if test_df is None or predictions is None:\n",
    "        print(\"❌ テストデータまたは予測結果がありません\")\n",
    "        return None\n",
    "    \n",
    "    print(f\"📊 提出データ: {len(predictions):,}件\")\n",
    "    \n",
    "    # sample_submission.csvを参考にして正しい形式で作成\n",
    "    # row_id,Category:Misconception の形式が必要\n",
    "    \n",
    "    # テストデータにrow_idが含まれているか確認\n",
    "    if 'row_id' in test_df.columns:\n",
    "        row_ids = test_df['row_id'].tolist()\n",
    "    else:\n",
    "        # row_idがない場合、testデータの開始IDを推定（通常は36696から）\n",
    "        print(\"⚠️ row_idが見つかりません。推定値を使用します...\")\n",
    "        start_id = 36696  # sample_submissionの開始ID\n",
    "        row_ids = list(range(start_id, start_id + len(test_df)))\n",
    "    \n",
    "    # Kaggle要求形式：各予測を \"Category:Misconception\" 形式に変換\n",
    "    print(\"🔧 Kaggle提出形式に変換中...\")\n",
    "    formatted_predictions = []\n",
    "    \n",
    "    for i, pred in enumerate(predictions):\n",
    "        # predは \"True_Correct False_Neither False_Misconception\" のようなスペース区切り\n",
    "        pred_categories = pred.split()[:3]  # TOP3に限定\n",
    "        \n",
    "        # 各カテゴリを \"Category:Misconception\" 形式に変換\n",
    "        formatted_parts = []\n",
    "        for category in pred_categories:\n",
    "            if category.endswith('_Misconception'):\n",
    "                # Misconceptionカテゴリの場合、実際の誤概念名が必要\n",
    "                # ここでは簡易的に \"Incomplete\" を使用（実際は予測結果から取得）\n",
    "                formatted_parts.append(f\"{category}:Incomplete\")\n",
    "            else:\n",
    "                # 他のカテゴリの場合はNA\n",
    "                formatted_parts.append(f\"{category}:NA\")\n",
    "        \n",
    "        # スペース区切りで結合\n",
    "        formatted_pred = \" \".join(formatted_parts)\n",
    "        formatted_predictions.append(formatted_pred)\n",
    "        \n",
    "        # 最初の5件をサンプル表示\n",
    "        if i < 5:\n",
    "            print(f\"  サンプル {i+1}: {formatted_pred}\")\n",
    "    \n",
    "    # 提出用データフレーム作成（正しいKaggle形式）\n",
    "    submission_df = pd.DataFrame({\n",
    "        'row_id': row_ids,\n",
    "        'Category:Misconception': formatted_predictions\n",
    "    })\n",
    "    \n",
    "    print(f\"✅ 提出データフレーム作成完了: {submission_df.shape}\")\n",
    "    print(f\"📝 列: {list(submission_df.columns)}\")\n",
    "    \n",
    "    # サンプル表示\n",
    "    print(f\"\\n📋 提出データサンプル:\")\n",
    "    print(submission_df.head(10).to_string(index=False))\n",
    "    \n",
    "    # ファイル保存\n",
    "    try:\n",
    "        submission_df.to_csv(output_path, index=False)\n",
    "        print(f\"\\n💾 提出ファイル保存完了: {output_path}\")\n",
    "        \n",
    "        # ファイルサイズ確認\n",
    "        file_size = os.path.getsize(output_path)\n",
    "        print(f\"📏 ファイルサイズ: {file_size:,} bytes ({file_size/1024:.1f} KB)\")\n",
    "        \n",
    "        # 形式確認\n",
    "        check_df = pd.read_csv(output_path)\n",
    "        print(f\"✅ 提出ファイル検証: {check_df.shape}\")\n",
    "        required_cols = ['row_id', 'Category:Misconception']\n",
    "        cols_present = all(col in check_df.columns for col in required_cols)\n",
    "        print(f\"   必要列存在確認: {cols_present}\")\n",
    "        \n",
    "        # 予測形式チェック\n",
    "        sample_predictions = check_df['Category:Misconception'].head(5).tolist()\n",
    "        print(f\"🔍 予測形式サンプル:\")\n",
    "        for i, pred in enumerate(sample_predictions):\n",
    "            pred_parts = pred.split()\n",
    "            print(f\"   {i+1}: {pred} (要素数: {len(pred_parts)})\")\n",
    "            \n",
    "        print(f\"\\n📊 提出ファイル最終確認:\")\n",
    "        print(f\"   ✅ 形式: Kaggle MAP競技形式（row_id, Category:Misconception）\")\n",
    "        print(f\"   ✅ 件数: {len(check_df):,}件\")\n",
    "        print(f\"   ✅ 列名: {list(check_df.columns)}\")\n",
    "        \n",
    "        return submission_df\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"❌ ファイル保存エラー: {e}\")\n",
    "        return None\n",
    "\n",
    "# 提出ファイルの作成\n",
    "if test_predictions is not None and test_df is not None:\n",
    "    print(\"📤 提出ファイルを作成します...\")\n",
    "    submission_df = create_submission_file(test_df, test_predictions, \"submission.csv\")\n",
    "    \n",
    "    if submission_df is not None:\n",
    "        print(\"🎉 提出ファイル作成完了!\")\n",
    "        print(f\"📋 最終確認:\")\n",
    "        print(f\"   ファイル名: submission.csv\")\n",
    "        print(f\"   データ件数: {len(submission_df):,}\")\n",
    "        print(f\"   予測形式: Kaggle MAP形式 (row_id, Category:Misconception)\")\n",
    "        print(\"\\n🏆 Kaggleコンペティションに提出準備完了!\")\n",
    "        \n",
    "        # 最終チェック用統計\n",
    "        print(f\"\\n📈 提出ファイル統計:\")\n",
    "        all_pred_in_submission = \" \".join(submission_df['Category:Misconception']).split()\n",
    "        unique_preds = set(all_pred_in_submission)\n",
    "        print(f\"   使用されたユニークなラベル数: {len(unique_preds)}\")\n",
    "        print(f\"   ラベル一覧: {sorted(unique_preds)}\")\n",
    "    else:\n",
    "        print(\"❌ 提出ファイル作成に失敗しました\")\n",
    "else:\n",
    "    print(\"❌ 必要なデータが準備されていません。前のセルを実行してください。\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf5faea7",
   "metadata": {
    "papermill": {
     "duration": 0.003368,
     "end_time": "2025-07-21T09:43:50.429414",
     "exception": false,
     "start_time": "2025-07-21T09:43:50.426046",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 🎯 Summary & Performance Notes\n",
    "\n",
    "### 📊 実行結果サマリー\n",
    "このノートブックでは以下を実装しました：\n",
    "\n",
    "1. **🤖 事前訓練済みモデル読み込み**: KaggleにアップロードされたGemma-2-2b-itモデル\n",
    "2. **📊 テストデータ処理**: math misconceptionコンペティションのtest.csv\n",
    "3. **🔮 効率的な推論**: バッチ処理による高速予測\n",
    "4. **📈 MAP@3形式出力**: TOP-3予測の生成\n",
    "5. **📤 提出準備**: Kaggle形式のsubmission.csv作成\n",
    "\n",
    "### 🚀 使用技術\n",
    "- **モデル**: `google/gemma-2-2b-it` (~2.6B parameters)\n",
    "- **フレームワーク**: PyTorch + Transformers\n",
    "- **推論**: 事前訓練済みモデル使用（追加訓練なし）\n",
    "- **評価**: MAP@3 (Mean Average Precision at 3)\n",
    "\n",
    "### ⚡ パフォーマンス最適化\n",
    "- バッチ処理による効率的な推論\n",
    "- 適応的バッチサイズ（CPU: 4, GPU: 8）\n",
    "- FP16使用（GPU環境）\n",
    "- メモリ効率的なデータローダー\n",
    "\n",
    "### 📝 使用方法\n",
    "1. Kaggleで事前訓練済みモデルをデータセットとしてアップロード\n",
    "2. MODEL_DATA_PATHを正しいデータセット名に変更\n",
    "3. 全セルを順番に実行\n",
    "4. `Gemma_2b_submission.csv`が生成される\n",
    "5. KaggleコンペティションにCSVファイルを提出\n",
    "\n",
    "### 🔧 トラブルシューティング\n",
    "- **メモリ不足**: バッチサイズを下げる\n",
    "- **モデル読み込み失敗**: データセット名とパスを確認\n",
    "- **CUDA OOM**: CPUモードに切り替え\n",
    "\n",
    "**🏆 Good luck with your submission!**"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 12957508,
     "isSourceIdPinned": false,
     "sourceId": 104383,
     "sourceType": "competition"
    },
    {
     "isSourceIdPinned": false,
     "modelId": 404697,
     "modelInstanceId": 385485,
     "sourceId": 480357,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 31090,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 101.086205,
   "end_time": "2025-07-21T09:43:54.171809",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-07-21T09:42:13.085604",
   "version": "2.6.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "09f0fae7fc254bf9b5d2d4af08fd4193": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_2a76706e910148cf9d055304b954d051",
       "placeholder": "​",
       "style": "IPY_MODEL_0ed5f1e78f5b4f35a651b4e5d3cca425",
       "tabbable": null,
       "tooltip": null,
       "value": "Loading checkpoint shards: 100%"
      }
     },
     "0ed5f1e78f5b4f35a651b4e5d3cca425": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "2a76706e910148cf9d055304b954d051": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "2be7eece0bc646a6a6fbf7be93ffdbd1": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "7a0b394e1bee44c8af2854ee1371c6cc": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "7e38e43016354f0b8b0fcb1201572de8": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_2be7eece0bc646a6a6fbf7be93ffdbd1",
       "max": 3.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_896ca728e405431f89276c0a2e63bb60",
       "tabbable": null,
       "tooltip": null,
       "value": 3.0
      }
     },
     "896ca728e405431f89276c0a2e63bb60": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "af4d8e5aaab34faca66dbd848168585b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "be1808ffd211462c8ff25902fcef3562": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_7a0b394e1bee44c8af2854ee1371c6cc",
       "placeholder": "​",
       "style": "IPY_MODEL_af4d8e5aaab34faca66dbd848168585b",
       "tabbable": null,
       "tooltip": null,
       "value": " 3/3 [00:45&lt;00:00, 12.75s/it]"
      }
     },
     "cb8c9616ab504e89a00294a06a82f9af": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "f8b2d2e344ae4d82af49f5c7c2d44afd": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_09f0fae7fc254bf9b5d2d4af08fd4193",
        "IPY_MODEL_7e38e43016354f0b8b0fcb1201572de8",
        "IPY_MODEL_be1808ffd211462c8ff25902fcef3562"
       ],
       "layout": "IPY_MODEL_cb8c9616ab504e89a00294a06a82f9af",
       "tabbable": null,
       "tooltip": null
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
