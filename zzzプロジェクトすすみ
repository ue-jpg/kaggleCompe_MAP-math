はじめた　7/19

とりあえずコパイに全部つくらせてトレインを走らせて寝たい

とりあえずGemma 2b でもっとも基本的なもでるをつくらせた

特徴量をうまく抽出する必要性を感じている
ミスコンセプションのカテゴリがfixされてるのかわからない問題がある

１回いまの超基本のモデルでコラボでトレインをまわして結果をみようと思います！

google/gemma-3-4b-it を今回はつかってみるよ！
これだと直接クラシフィケーションに適用できないっていわれてかわりにPEFTするっていわれたよ
はじめからそうしてほしかったよ！

GemminiががんばってPEFTの設定をしているが自分はタバコを吸って早く寝たい

A100をつかってもgoogle/gemma-3-4b-itではout of memoryだった
だから3-1bに変えて試している　どんだけメモリ使うんだ

一度サブミッドの方法を超簡単なモデルでためしてやってみたほうがいい
gemmaは重すぎてサブミッドできない可能性がある

peftの設定ができていないことをコラボでトレインを開始してから気付いた
だからすごいメモリやばかったんだ
peft設定してもう一回やらないと

やっぱりgoogle/gemma-3n-E4B-itをつかうことにした
3nの方がメモリの使用がより効率的らしい

カグルのノートブック環境に合わせて、コラボのランタイムをTPU v2-8 にした
結局うまくいかなかったのでA100にした

バッチサイズが4だけど1とかいうエラーがでた　これは未解決

結局メモリが足りないエラーになった、やっぱりGemma3nを使うのはあきらめるしかないのかもしれない
google/gemma-2-2b-itをつかうことにした、もともとの目的からはそれるがリソースの問題なら仕方がない、約３時間で訓練が終わるらしい
無理なことがわかっただけでもよかった

すこしバッチサイズの勉強をした、今回は8でまわすことにした、16にしたらアウトオブメモリーだったから
色々モデルを変えて試してみて、どこまでのモデルなら使えるか？そもそもメモリ使用量が何に対してあがっているのか検証する必要がある
もしかしたら3nは無理でも3-4bとかならまわる可能性もある

