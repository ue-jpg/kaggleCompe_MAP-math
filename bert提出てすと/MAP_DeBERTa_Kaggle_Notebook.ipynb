{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e923ddc8",
   "metadata": {},
   "source": [
    "# ğŸ¯ MAP Competition: DeBERTa-v3-xsmall for 6-Class Text Classification\n",
    "\n",
    "## Overview\n",
    "ã“ã®ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯ã¯ã€æ•°å­¦çš„èª¤è§£ï¼ˆMath Misconceptionï¼‰åˆ†é¡ã‚³ãƒ³ãƒšãƒ†ã‚£ã‚·ãƒ§ãƒ³ç”¨ã®DeBERTa-v3-xsmallãƒ¢ãƒ‡ãƒ«ã‚’å®Ÿè£…ã—ã¦ã„ã¾ã™ã€‚\n",
    "\n",
    "### Target Classes (6åˆ†é¡)\n",
    "- **True_Correct**: æ­£è§£ã§æ­£ã—ã„èª¬æ˜\n",
    "- **True_Neither**: æ­£è§£ã ãŒæ›–æ˜§ãªèª¬æ˜\n",
    "- **True_Misconception**: æ­£è§£ã ãŒèª¤ã£ãŸæ¦‚å¿µã®èª¬æ˜\n",
    "- **False_Correct**: ä¸æ­£è§£ã ãŒæ­£ã—ã„æ¦‚å¿µã®èª¬æ˜\n",
    "- **False_Neither**: ä¸æ­£è§£ã§æ›–æ˜§ãªèª¬æ˜\n",
    "- **False_Misconception**: ä¸æ­£è§£ã§èª¤ã£ãŸæ¦‚å¿µã®èª¬æ˜\n",
    "\n",
    "### Model Architecture\n",
    "- **Base Model**: microsoft/deberta-v3-xsmall\n",
    "- **Parameters**: ~70M\n",
    "- **Max Length**: 512 tokens\n",
    "- **Evaluation Metric**: MAP@3\n",
    "\n",
    "### Competition Format\n",
    "- Input: QuestionText + MC_Answer + StudentExplanation\n",
    "- Output: Top 3 predicted categories (space-separated)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6716e92",
   "metadata": {},
   "source": [
    "## ğŸ“¦ Install Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63dcd4b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kaggleç’°å¢ƒã§å¿…è¦ãªãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«\n",
    "# Kaggleã§ã¯é€šå¸¸ã€transformersã¨accelerateãŒå¿…è¦\n",
    "\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "def install_package(package):\n",
    "    \"\"\"ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã™ã‚‹é–¢æ•°\"\"\"\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package])\n",
    "\n",
    "# å¿…è¦ãªãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«\n",
    "try:\n",
    "    import transformers\n",
    "    print(f\"âœ… transformers already installed: {transformers.__version__}\")\n",
    "except ImportError:\n",
    "    print(\"ğŸ“¦ Installing transformers...\")\n",
    "    install_package(\"transformers\")\n",
    "\n",
    "try:\n",
    "    import accelerate\n",
    "    print(f\"âœ… accelerate already installed: {accelerate.__version__}\")\n",
    "except ImportError:\n",
    "    print(\"ğŸ“¦ Installing accelerate...\")\n",
    "    install_package(\"accelerate>=0.26.0\")\n",
    "\n",
    "try:\n",
    "    import sentencepiece\n",
    "    print(f\"âœ… sentencepiece already installed: {sentencepiece.__version__}\")\n",
    "except ImportError:\n",
    "    print(\"ğŸ“¦ Installing sentencepiece...\")\n",
    "    install_package(\"sentencepiece\")\n",
    "\n",
    "print(\"ğŸ‰ All required libraries are ready!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c0a77d6",
   "metadata": {},
   "source": [
    "## ğŸ“š Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00896bed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# åŸºæœ¬ãƒ©ã‚¤ãƒ–ãƒ©ãƒª\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "\n",
    "# æ©Ÿæ¢°å­¦ç¿’ãƒ©ã‚¤ãƒ–ãƒ©ãƒª\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# Transformersãƒ©ã‚¤ãƒ–ãƒ©ãƒª\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSequenceClassification,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    DataCollatorWithPadding,\n",
    ")\n",
    "\n",
    "# Scikit-learnãƒ©ã‚¤ãƒ–ãƒ©ãƒª\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# è­¦å‘Šã‚’éè¡¨ç¤º\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# ãƒ‡ãƒãƒƒã‚°æƒ…å ±è¡¨ç¤º\n",
    "print(\"ğŸ”§ Environment Information:\")\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA version: {torch.version.cuda}\")\n",
    "    print(f\"GPU device: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"GPU memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n",
    "else:\n",
    "    print(\"Running on CPU\")\n",
    "\n",
    "# Kaggleã®ãƒ‡ãƒ¼ã‚¿ãƒ‘ã‚¹è¨­å®š\n",
    "KAGGLE_INPUT_PATH = \"/kaggle/input\"\n",
    "if os.path.exists(KAGGLE_INPUT_PATH):\n",
    "    print(f\"ğŸ“ Kaggle environment detected: {KAGGLE_INPUT_PATH}\")\n",
    "    # MAP - Charting Student Math Misunderstandings ã‚³ãƒ³ãƒšãƒ†ã‚£ã‚·ãƒ§ãƒ³\n",
    "    DATA_PATH = \"/kaggle/input/map-charting-student-math-misunderstandings\"\n",
    "    print(f\"ğŸ¯ Competition data path: {DATA_PATH}\")\n",
    "else:\n",
    "    print(\"ğŸ“ Local environment detected\")\n",
    "    DATA_PATH = \".\"\n",
    "\n",
    "print(\"âœ… All libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ede0e958",
   "metadata": {},
   "source": [
    "## ğŸ”§ Define Dataset Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d035a642",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MathMisconceptionDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Math Misconception Dataset for PyTorch\n",
    "    \n",
    "    6åˆ†é¡ã‚¿ã‚¹ã‚¯ç”¨ã®ã‚«ã‚¹ã‚¿ãƒ ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ:\n",
    "    - True_Correct, True_Neither, True_Misconception\n",
    "    - False_Correct, False_Neither, False_Misconception\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, texts, labels, tokenizer, max_length=512):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            texts (list): ãƒ†ã‚­ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã®ãƒªã‚¹ãƒˆ\n",
    "            labels (list): ãƒ©ãƒ™ãƒ«ãƒ‡ãƒ¼ã‚¿ã®ãƒªã‚¹ãƒˆ\n",
    "            tokenizer: DeBERTaãƒˆãƒ¼ã‚¯ãƒŠã‚¤ã‚¶ãƒ¼\n",
    "            max_length (int): æœ€å¤§ãƒˆãƒ¼ã‚¯ãƒ³é•·\n",
    "        \"\"\"\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = str(self.texts[idx])\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        # DeBERTaãƒˆãƒ¼ã‚¯ãƒŠã‚¤ã‚¶ãƒ¼ã§ãƒ†ã‚­ã‚¹ãƒˆã‚’ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰\n",
    "        encoding = self.tokenizer(\n",
    "            text,\n",
    "            truncation=True,\n",
    "            padding=\"max_length\",\n",
    "            max_length=self.max_length,\n",
    "            return_tensors=\"pt\",\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            \"input_ids\": encoding[\"input_ids\"].flatten(),\n",
    "            \"attention_mask\": encoding[\"attention_mask\"].flatten(),\n",
    "            \"labels\": torch.tensor(label, dtype=torch.long),\n",
    "        }\n",
    "\n",
    "print(\"âœ… MathMisconceptionDataset class defined successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a50be3bf",
   "metadata": {},
   "source": [
    "## ğŸ“Š Load and Prepare Competition Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e746b276",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_prepare_data():\n",
    "    \"\"\"ã‚³ãƒ³ãƒšãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿ã¨å‰å‡¦ç†ï¼ˆ6åˆ†é¡å½¢å¼ï¼‰\"\"\"\n",
    "    print(\"=\" * 60)\n",
    "    print(\"ğŸ“Š ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ã¨å‰å‡¦ç†ï¼ˆ6åˆ†é¡å½¢å¼ï¼‰\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Kaggleã‚³ãƒ³ãƒšãƒ†ã‚£ã‚·ãƒ§ãƒ³: MAP - Charting Student Math Misunderstandings\n",
    "    # æ­£ç¢ºãªãƒ‡ãƒ¼ã‚¿ãƒ‘ã‚¹: /kaggle/input/map-charting-student-math-misunderstandings/\n",
    "    try:\n",
    "        # Kaggleç’°å¢ƒã§ã®ãƒ‘ã‚¹\n",
    "        if os.path.exists(\"/kaggle/input\"):\n",
    "            # Kaggleç’°å¢ƒ\n",
    "            kaggle_data_path = \"/kaggle/input/map-charting-student-math-misunderstandings\"\n",
    "            train_path = f\"{kaggle_data_path}/train.csv\"\n",
    "            test_path = f\"{kaggle_data_path}/test.csv\"\n",
    "        else:\n",
    "            # ãƒ­ãƒ¼ã‚«ãƒ«ç’°å¢ƒ - map_dataãƒ•ã‚©ãƒ«ãƒ€ã‚’ä½¿ç”¨\n",
    "            train_path = f\"{DATA_PATH}/map_data/train.csv\"\n",
    "            test_path = f\"{DATA_PATH}/map_data/test.csv\"\n",
    "            \n",
    "        print(f\"ğŸ“ ä½¿ç”¨ã™ã‚‹ãƒ‘ã‚¹:\")\n",
    "        print(f\"   Train: {train_path}\")\n",
    "        print(f\"   Test: {test_path}\")\n",
    "            \n",
    "        train_df = pd.read_csv(train_path)\n",
    "        test_df = pd.read_csv(test_path)\n",
    "        \n",
    "        print(f\"âœ… ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿æˆåŠŸ!\")\n",
    "        print(f\"ğŸ“ Train path: {train_path}\")\n",
    "        print(f\"ğŸ“ Test path: {test_path}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}\")\n",
    "        return None, None\n",
    "\n",
    "    print(f\"ğŸ“ˆ è¨“ç·´ãƒ‡ãƒ¼ã‚¿å½¢çŠ¶: {train_df.shape}\")\n",
    "    print(f\"ğŸ“ˆ ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿å½¢çŠ¶: {test_df.shape}\")\n",
    "    \n",
    "    # ãƒ‡ãƒ¼ã‚¿ç¢ºèª\n",
    "    print(\"\\nğŸ“‹ è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã®åˆ—:\")\n",
    "    print(train_df.columns.tolist())\n",
    "    \n",
    "    print(\"\\nğŸ“‹ Categoryåˆ†å¸ƒ:\")\n",
    "    if 'Category' in train_df.columns:\n",
    "        print(train_df[\"Category\"].value_counts())\n",
    "    else:\n",
    "        print(\"âŒ 'Category'åˆ—ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“\")\n",
    "        return None, None\n",
    "\n",
    "    # NaNå€¤ã®ç¢ºèªã¨é™¤å»\n",
    "    print(f\"\\nğŸ§¹ ãƒ‡ãƒ¼ã‚¿ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°:\")\n",
    "    before_len = len(train_df)\n",
    "    \n",
    "    # å¿…è¦ãªåˆ—ã®å­˜åœ¨ç¢ºèª\n",
    "    required_cols = [\"Category\", \"StudentExplanation\"]\n",
    "    missing_cols = [col for col in required_cols if col not in train_df.columns]\n",
    "    if missing_cols:\n",
    "        print(f\"âŒ å¿…è¦ãªåˆ—ãŒä¸è¶³: {missing_cols}\")\n",
    "        return None, None\n",
    "    \n",
    "    train_df = train_df.dropna(subset=required_cols)\n",
    "    after_len = len(train_df)\n",
    "    print(f\"NaNé™¤å»: {before_len} -> {after_len} ({before_len - after_len}è¡Œå‰Šé™¤)\")\n",
    "\n",
    "    # å¼·åŒ–ã•ã‚ŒãŸãƒ†ã‚­ã‚¹ãƒˆç‰¹å¾´é‡ã®ä½œæˆ\n",
    "    def create_enhanced_text(row):\n",
    "        \"\"\"Question + MC_Answer + Explanation ã‚’çµåˆã—ãŸå¼·åŒ–ãƒ†ã‚­ã‚¹ãƒˆ\"\"\"\n",
    "        question = str(row.get(\"QuestionText\", \"\")) if pd.notna(row.get(\"QuestionText\")) else \"\"\n",
    "        mc_answer = str(row.get(\"MC_Answer\", \"\")) if pd.notna(row.get(\"MC_Answer\")) else \"\"\n",
    "        explanation = str(row.get(\"StudentExplanation\", \"\")) if pd.notna(row.get(\"StudentExplanation\")) else \"\"\n",
    "        \n",
    "        # DeBERTaç”¨ã®æ§‹é€ åŒ–ãƒ†ã‚­ã‚¹ãƒˆ\n",
    "        enhanced_text = f\"Question: {question} Selected Answer: {mc_answer} Explanation: {explanation}\"\n",
    "        return enhanced_text\n",
    "\n",
    "    print(\"\\nğŸ”§ å¼·åŒ–ãƒ†ã‚­ã‚¹ãƒˆç‰¹å¾´é‡ä½œæˆä¸­...\")\n",
    "    train_df[\"enhanced_text\"] = train_df.apply(create_enhanced_text, axis=1)\n",
    "    test_df[\"enhanced_text\"] = test_df.apply(create_enhanced_text, axis=1)\n",
    "    \n",
    "    # 6ã¤ã®ã‚«ãƒ†ã‚´ãƒªã®ç¢ºèª\n",
    "    unique_categories = sorted(train_df[\"Category\"].unique())\n",
    "    print(f\"\\nğŸ“Š ã‚«ãƒ†ã‚´ãƒªæƒ…å ±:\")\n",
    "    print(f\"ãƒ¦ãƒ‹ãƒ¼ã‚¯ãªã‚«ãƒ†ã‚´ãƒªæ•°: {len(unique_categories)}\")\n",
    "    print(\"ã‚«ãƒ†ã‚´ãƒªè©³ç´°:\")\n",
    "    for i, cat in enumerate(unique_categories):\n",
    "        count = (train_df[\"Category\"] == cat).sum()\n",
    "        percentage = count / len(train_df) * 100\n",
    "        print(f\"  {i}: {cat} ({count:,}ä»¶, {percentage:.1f}%)\")\n",
    "    \n",
    "    # ã‚µãƒ³ãƒ—ãƒ«ãƒ†ã‚­ã‚¹ãƒˆã®è¡¨ç¤º\n",
    "    print(f\"\\nğŸ“ å¼·åŒ–ãƒ†ã‚­ã‚¹ãƒˆã‚µãƒ³ãƒ—ãƒ«:\")\n",
    "    sample_text = train_df[\"enhanced_text\"].iloc[0]\n",
    "    print(f\"Length: {len(sample_text)} characters\")\n",
    "    print(f\"Sample: {sample_text[:200]}...\")\n",
    "    \n",
    "    return train_df, test_df\n",
    "\n",
    "# ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿å®Ÿè¡Œ\n",
    "train_df, test_df = load_and_prepare_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63abc52a",
   "metadata": {},
   "source": [
    "## ğŸ¤– Initialize DeBERTa Model and Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfb712f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_model(num_labels=6, model_name=\"microsoft/deberta-v3-xsmall\"):\n",
    "    \"\"\"DeBERTa-v3-xsmallãƒ¢ãƒ‡ãƒ«ã¨ãƒˆãƒ¼ã‚¯ãƒŠã‚¤ã‚¶ãƒ¼ã®æº–å‚™\"\"\"\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"ğŸ¤– DeBERTaãƒ¢ãƒ‡ãƒ«æº–å‚™: {model_name}\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    # ãƒ‡ãƒã‚¤ã‚¹è¨­å®šï¼ˆKaggleã®GPUç’°å¢ƒã«æœ€é©åŒ–ï¼‰\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"ğŸ–¥ï¸  ä½¿ç”¨ãƒ‡ãƒã‚¤ã‚¹: {device}\")\n",
    "    \n",
    "    if torch.cuda.is_available():\n",
    "        print(f\"ğŸš€ GPUæƒ…å ±: {torch.cuda.get_device_name(0)}\")\n",
    "        print(f\"ğŸ’¾ GPU ãƒ¡ãƒ¢ãƒª: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n",
    "\n",
    "    try:\n",
    "        # ãƒˆãƒ¼ã‚¯ãƒŠã‚¤ã‚¶ãƒ¼ã®èª­ã¿è¾¼ã¿\n",
    "        print(\"ğŸ“ DeBERTaãƒˆãƒ¼ã‚¯ãƒŠã‚¤ã‚¶ãƒ¼èª­ã¿è¾¼ã¿ä¸­...\")\n",
    "        tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "        \n",
    "        # ãƒ‘ãƒ‡ã‚£ãƒ³ã‚°ãƒˆãƒ¼ã‚¯ãƒ³ã®ç¢ºèª\n",
    "        print(f\"ğŸ”– ãƒ‘ãƒ‡ã‚£ãƒ³ã‚°ãƒˆãƒ¼ã‚¯ãƒ³: {tokenizer.pad_token}\")\n",
    "        print(f\"ğŸ“ æœ€å¤§ãƒˆãƒ¼ã‚¯ãƒ³é•·: {tokenizer.model_max_length}\")\n",
    "\n",
    "        # 6åˆ†é¡ç”¨ãƒ¢ãƒ‡ãƒ«ã®èª­ã¿è¾¼ã¿\n",
    "        print(\"ğŸ§  DeBERTaãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿ä¸­...\")\n",
    "        model = AutoModelForSequenceClassification.from_pretrained(\n",
    "            model_name,\n",
    "            num_labels=num_labels,\n",
    "            torch_dtype=torch.float16 if device.type == \"cuda\" else torch.float32,\n",
    "        )\n",
    "\n",
    "        # ãƒ‡ãƒã‚¤ã‚¹ã«ç§»å‹•\n",
    "        model = model.to(device)\n",
    "        \n",
    "        # ãƒ¢ãƒ‡ãƒ«æƒ…å ±è¡¨ç¤º\n",
    "        total_params = sum(p.numel() for p in model.parameters())\n",
    "        trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "        \n",
    "        print(f\"âœ… DeBERTaãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿å®Œäº†!\")\n",
    "        print(f\"ğŸ“Š åˆ†é¡ã‚¯ãƒ©ã‚¹æ•°: {num_labels}\")\n",
    "        print(f\"ğŸ“ˆ ç·ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°: {total_params:,}\")\n",
    "        print(f\"ğŸ¯ è¨“ç·´å¯èƒ½ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°: {trainable_params:,}\")\n",
    "        print(f\"ğŸ’¡ ãƒ¢ãƒ‡ãƒ«ã‚µã‚¤ã‚º: ~{total_params / 1e6:.1f}M parameters\")\n",
    "\n",
    "        return model, tokenizer, device\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ DeBERTaãƒ¢ãƒ‡ãƒ«ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—: {e}\")\n",
    "        print(\"\\nğŸ”§ ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°:\")\n",
    "        print(\"1. ã‚¤ãƒ³ã‚¿ãƒ¼ãƒãƒƒãƒˆæ¥ç¶šç¢ºèª\")\n",
    "        print(\"2. Kaggleç’°å¢ƒã§ã®ãƒ¢ãƒ‡ãƒ«ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰åˆ¶é™ç¢ºèª\")\n",
    "        print(\"3. ãƒ¡ãƒ¢ãƒªä¸è¶³ã®å¯èƒ½æ€§ç¢ºèª\")\n",
    "        raise e\n",
    "\n",
    "# ãƒ¢ãƒ‡ãƒ«åˆæœŸåŒ–ã®å®Ÿè¡Œ\n",
    "if train_df is not None:\n",
    "    model, tokenizer, device = prepare_model(num_labels=6)\n",
    "else:\n",
    "    print(\"âŒ ãƒ‡ãƒ¼ã‚¿ãŒèª­ã¿è¾¼ã¾ã‚Œã¦ã„ãªã„ãŸã‚ã€ãƒ¢ãƒ‡ãƒ«åˆæœŸåŒ–ã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba2b64ba",
   "metadata": {},
   "source": [
    "## âš™ï¸ Create Training Arguments and Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7faf2eed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kaggleç’°å¢ƒã«æœ€é©åŒ–ã•ã‚ŒãŸãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°è¨­å®š\n",
    "def create_training_config(device, output_dir=\"./deberta_model\"):\n",
    "    \"\"\"Kaggleç’°å¢ƒç”¨ã®ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°è¨­å®š\"\"\"\n",
    "    \n",
    "    # GPUåˆ©ç”¨å¯èƒ½æ€§ã«åŸºã¥ãè¨­å®šèª¿æ•´\n",
    "    if torch.cuda.is_available():\n",
    "        # GPUç’°å¢ƒ: ã‚ˆã‚Šå¤§ããªãƒãƒƒãƒã‚µã‚¤ã‚ºã¨fp16ä½¿ç”¨\n",
    "        batch_size = 8  # Kaggle GPUåˆ¶é™ã«åˆã‚ã›ã¦èª¿æ•´\n",
    "        gradient_accumulation = 4  # å®ŸåŠ¹ãƒãƒƒãƒã‚µã‚¤ã‚º = 32\n",
    "        use_fp16 = True\n",
    "        epochs = 3  # Kaggleæ™‚é–“åˆ¶é™ã«åˆã‚ã›ã¦èª¿æ•´\n",
    "    else:\n",
    "        # CPUç’°å¢ƒ: å°ã•ãªãƒãƒƒãƒã‚µã‚¤ã‚º\n",
    "        batch_size = 2\n",
    "        gradient_accumulation = 8\n",
    "        use_fp16 = False\n",
    "        epochs = 2\n",
    "    \n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=output_dir,\n",
    "        num_train_epochs=epochs,\n",
    "        per_device_train_batch_size=batch_size,\n",
    "        per_device_eval_batch_size=batch_size,\n",
    "        gradient_accumulation_steps=gradient_accumulation,\n",
    "        \n",
    "        # å­¦ç¿’ç‡ã¨ã‚ªãƒ—ãƒ†ã‚£ãƒã‚¤ã‚¶ãƒ¼è¨­å®š\n",
    "        learning_rate=3e-5,  # DeBERTaæ¨å¥¨å€¤\n",
    "        weight_decay=0.01,\n",
    "        warmup_steps=200,\n",
    "        \n",
    "        # è©•ä¾¡ã¨ãƒ­ã‚®ãƒ³ã‚°\n",
    "        eval_strategy=\"steps\",\n",
    "        eval_steps=200,\n",
    "        logging_steps=50,\n",
    "        \n",
    "        # ãƒ¢ãƒ‡ãƒ«ä¿å­˜\n",
    "        save_strategy=\"steps\",\n",
    "        save_steps=400,\n",
    "        save_total_limit=2,\n",
    "        load_best_model_at_end=True,\n",
    "        metric_for_best_model=\"map3\",\n",
    "        greater_is_better=True,\n",
    "        \n",
    "        # æœ€é©åŒ–è¨­å®š\n",
    "        fp16=use_fp16,\n",
    "        dataloader_pin_memory=False,\n",
    "        remove_unused_columns=False,\n",
    "        report_to=None,  # wandbãªã©ã®ãƒ­ã‚®ãƒ³ã‚°ã‚’ç„¡åŠ¹\n",
    "        \n",
    "        # ãã®ä»–\n",
    "        seed=42,\n",
    "        data_seed=42,\n",
    "    )\n",
    "    \n",
    "    print(\"âš™ï¸ ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°è¨­å®š:\")\n",
    "    print(f\"  ğŸ“Š ã‚¨ãƒãƒƒã‚¯æ•°: {epochs}\")\n",
    "    print(f\"  ğŸ“¦ ãƒãƒƒãƒã‚µã‚¤ã‚º: {batch_size}\")\n",
    "    print(f\"  ğŸ”„ å‹¾é…è“„ç©: {gradient_accumulation} (å®ŸåŠ¹ãƒãƒƒãƒ: {batch_size * gradient_accumulation})\")\n",
    "    print(f\"  ğŸ“ˆ å­¦ç¿’ç‡: {training_args.learning_rate}\")\n",
    "    print(f\"  ğŸ¯ FP16ä½¿ç”¨: {use_fp16}\")\n",
    "    print(f\"  ğŸ’¾ å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª: {output_dir}\")\n",
    "    \n",
    "    return training_args\n",
    "\n",
    "# MAP@3ãƒ¡ãƒˆãƒªã‚¯ã‚¹è¨ˆç®—é–¢æ•°\n",
    "def compute_map3_metrics(eval_pred):\n",
    "    \"\"\"\n",
    "    MAP@3 (Mean Average Precision at 3) ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã®è¨ˆç®—\n",
    "    ã‚³ãƒ³ãƒšãƒ†ã‚£ã‚·ãƒ§ãƒ³ã®è©•ä¾¡æŒ‡æ¨™\n",
    "    \"\"\"\n",
    "    predictions, labels = eval_pred\n",
    "    \n",
    "    # ã‚½ãƒ•ãƒˆãƒãƒƒã‚¯ã‚¹ã§ç¢ºç‡ã«å¤‰æ›\n",
    "    predictions = torch.softmax(torch.tensor(predictions), dim=-1).numpy()\n",
    "    \n",
    "    map_scores = []\n",
    "    for i, true_label in enumerate(labels):\n",
    "        # å„ã‚µãƒ³ãƒ—ãƒ«ã®ä¸Šä½3ã¤ã®äºˆæ¸¬ã‚’å–å¾—\n",
    "        top3_indices = np.argsort(predictions[i])[::-1][:3]\n",
    "        \n",
    "        # MAPè¨ˆç®—: æ­£è§£ãŒä¸Šä½3ã¤ã«å«ã¾ã‚Œã‚‹ã‹ãƒã‚§ãƒƒã‚¯\n",
    "        score = 0.0\n",
    "        for j, pred_idx in enumerate(top3_indices):\n",
    "            if pred_idx == true_label:\n",
    "                score = 1.0 / (j + 1)  # 1ä½=1.0, 2ä½=0.5, 3ä½=0.33\n",
    "                break\n",
    "        map_scores.append(score)\n",
    "    \n",
    "    # å¹³å‡è¨ˆç®—\n",
    "    map3_score = np.mean(map_scores)\n",
    "    accuracy = accuracy_score(labels, np.argmax(predictions, axis=1))\n",
    "    \n",
    "    return {\n",
    "        \"map3\": map3_score,\n",
    "        \"accuracy\": accuracy,\n",
    "        \"eval_loss\": float(np.mean([1 - score for score in map_scores]))  # ç°¡æ˜“æå¤±\n",
    "    }\n",
    "\n",
    "print(\"âœ… ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°è¨­å®šã¨ãƒ¡ãƒˆãƒªã‚¯ã‚¹é–¢æ•°ãŒå®šç¾©ã•ã‚Œã¾ã—ãŸï¼\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fb5ef60",
   "metadata": {},
   "source": [
    "## ğŸš€ Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e056236",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(train_df, model, tokenizer, device):\n",
    "    \"\"\"DeBERTaãƒ¢ãƒ‡ãƒ«ã®ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°å®Ÿè¡Œ\"\"\"\n",
    "    print(\"=\" * 60)\n",
    "    print(\"ğŸš€ 6åˆ†é¡ãƒ¢ãƒ‡ãƒ« ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°é–‹å§‹\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # ãƒ©ãƒ™ãƒ«ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°\n",
    "    label_encoder = LabelEncoder()\n",
    "    train_df[\"encoded_labels\"] = label_encoder.fit_transform(train_df[\"Category\"])\n",
    "    \n",
    "    print(\"ğŸ·ï¸ ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ã•ã‚ŒãŸãƒ©ãƒ™ãƒ«:\")\n",
    "    for i, label in enumerate(label_encoder.classes_):\n",
    "        count = (train_df[\"encoded_labels\"] == i).sum()\n",
    "        print(f\"  {i}: {label} ({count:,}ä»¶)\")\n",
    "    \n",
    "    # ãƒ‡ãƒ¼ã‚¿åˆ†å‰²ï¼ˆã‚¯ãƒ©ã‚¹ä¸å‡è¡¡ã«å¯¾å¿œï¼‰\n",
    "    train_texts = train_df[\"enhanced_text\"].tolist()\n",
    "    train_labels = train_df[\"encoded_labels\"].tolist()\n",
    "    \n",
    "    print(f\"\\nğŸ“Š ãƒ‡ãƒ¼ã‚¿åˆ†å‰²å®Ÿè¡Œ...\")\n",
    "    try:\n",
    "        # Stratified splitï¼ˆã‚¯ãƒ©ã‚¹æ¯”ç‡ã‚’ä¿æŒï¼‰\n",
    "        X_train, X_val, y_train, y_val = train_test_split(\n",
    "            train_texts,\n",
    "            train_labels,\n",
    "            test_size=0.2,\n",
    "            random_state=42,\n",
    "            stratify=train_labels,\n",
    "        )\n",
    "        print(\"âœ… Stratified splité©ç”¨\")\n",
    "    except ValueError as e:\n",
    "        print(f\"âš ï¸ Stratified splitã«å¤±æ•—ã€é€šå¸¸ã®splitã‚’ä½¿ç”¨: {e}\")\n",
    "        X_train, X_val, y_train, y_val = train_test_split(\n",
    "            train_texts, train_labels, test_size=0.2, random_state=42\n",
    "        )\n",
    "    \n",
    "    print(f\"ğŸ“ˆ è¨“ç·´ãƒ‡ãƒ¼ã‚¿: {len(X_train):,}ä»¶\")\n",
    "    print(f\"ğŸ“ˆ æ¤œè¨¼ãƒ‡ãƒ¼ã‚¿: {len(X_val):,}ä»¶\")\n",
    "    \n",
    "    # ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆä½œæˆ\n",
    "    print(f\"\\nğŸ”§ PyTorchãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆä½œæˆä¸­...\")\n",
    "    train_dataset = MathMisconceptionDataset(\n",
    "        X_train, y_train, tokenizer, max_length=512\n",
    "    )\n",
    "    val_dataset = MathMisconceptionDataset(\n",
    "        X_val, y_val, tokenizer, max_length=512\n",
    "    )\n",
    "    \n",
    "    print(f\"âœ… è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ: {len(train_dataset)}ã‚µãƒ³ãƒ—ãƒ«\")\n",
    "    print(f\"âœ… æ¤œè¨¼ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ: {len(val_dataset)}ã‚µãƒ³ãƒ—ãƒ«\")\n",
    "    \n",
    "    # ãƒ‡ãƒ¼ã‚¿ã‚³ãƒ¬ãƒ¼ã‚¿ãƒ¼ï¼ˆå‹•çš„ãƒ‘ãƒ‡ã‚£ãƒ³ã‚°ï¼‰\n",
    "    data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "    \n",
    "    # ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°è¨­å®š\n",
    "    training_args = create_training_config(device)\n",
    "    \n",
    "    # Trainerã®åˆæœŸåŒ–\n",
    "    print(f\"\\nğŸ¯ TraineråˆæœŸåŒ–ä¸­...\")\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=train_dataset,\n",
    "        eval_dataset=val_dataset,\n",
    "        tokenizer=tokenizer,\n",
    "        data_collator=data_collator,\n",
    "        compute_metrics=compute_map3_metrics,\n",
    "    )\n",
    "    \n",
    "    # GPUä½¿ç”¨æ™‚ã®ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡è¡¨ç¤º\n",
    "    if torch.cuda.is_available():\n",
    "        print(f\"ğŸ–¥ï¸ GPUåˆæœŸãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡: {torch.cuda.memory_allocated() / 1e6:.1f} MB\")\n",
    "    \n",
    "    # ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°å®Ÿè¡Œ\n",
    "    print(f\"\\nğŸš€ ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°é–‹å§‹!\")\n",
    "    print(f\"â±ï¸ æ¨å®šæ™‚é–“: {training_args.num_train_epochs * len(train_dataset) // (training_args.per_device_train_batch_size * training_args.gradient_accumulation_steps) // 60 + 1} åˆ†\")\n",
    "    \n",
    "    try:\n",
    "        # è¨“ç·´å®Ÿè¡Œ\n",
    "        trainer.train()\n",
    "        \n",
    "        # GPUä½¿ç”¨æ™‚ã®æœ€çµ‚ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡\n",
    "        if torch.cuda.is_available():\n",
    "            print(f\"ğŸ–¥ï¸ GPUæœ€çµ‚ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡: {torch.cuda.memory_allocated() / 1e6:.1f} MB\")\n",
    "        \n",
    "        print(f\"âœ… ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°å®Œäº†!\")\n",
    "        \n",
    "        # æœ€çµ‚è©•ä¾¡\n",
    "        print(f\"\\nğŸ“Š æœ€çµ‚ãƒ¢ãƒ‡ãƒ«è©•ä¾¡:\")\n",
    "        eval_results = trainer.evaluate()\n",
    "        for key, value in eval_results.items():\n",
    "            print(f\"  ğŸ“ˆ {key}: {value:.4f}\")\n",
    "        \n",
    "        return trainer, label_encoder\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿ: {e}\")\n",
    "        print(f\"ğŸ’¡ ãƒ¡ãƒ¢ãƒªä¸è¶³ã®å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚ãƒãƒƒãƒã‚µã‚¤ã‚ºã‚’ä¸‹ã’ã¦ãã ã•ã„ã€‚\")\n",
    "        raise e\n",
    "\n",
    "# ãƒ¢ãƒ‡ãƒ«è¨“ç·´ã®å®Ÿè¡Œ\n",
    "if 'model' in locals() and 'tokenizer' in locals() and train_df is not None:\n",
    "    print(\"ğŸ¯ ãƒ¢ãƒ‡ãƒ«è¨“ç·´ã‚’é–‹å§‹ã—ã¾ã™...\")\n",
    "    trainer, label_encoder = train_model(train_df, model, tokenizer, device)\n",
    "    print(\"ğŸ‰ ãƒ¢ãƒ‡ãƒ«è¨“ç·´å®Œäº†!\")\n",
    "else:\n",
    "    print(\"âŒ å¿…è¦ãªå¤‰æ•°ãŒæº–å‚™ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚å‰ã®ã‚»ãƒ«ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bad5c65f",
   "metadata": {},
   "source": [
    "## ğŸ”® Generate Predictions for Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6978bcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_test_predictions(trainer, tokenizer, test_df, label_encoder):\n",
    "    \"\"\"ãƒ†ã‚¹ãƒˆã‚»ãƒƒãƒˆã«å¯¾ã™ã‚‹äºˆæ¸¬ç”Ÿæˆï¼ˆMAP@3å½¢å¼ï¼‰\"\"\"\n",
    "    print(\"=\" * 60)\n",
    "    print(\"ğŸ”® ãƒ†ã‚¹ãƒˆã‚»ãƒƒãƒˆäºˆæ¸¬ç”Ÿæˆ\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    if test_df is None or len(test_df) == 0:\n",
    "        print(\"âŒ ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ãŒåˆ©ç”¨ã§ãã¾ã›ã‚“\")\n",
    "        return None\n",
    "    \n",
    "    print(f\"ğŸ“Š ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿: {len(test_df):,}ä»¶\")\n",
    "    \n",
    "    # ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã®å‰å‡¦ç†\n",
    "    test_texts = test_df[\"enhanced_text\"].tolist()\n",
    "    \n",
    "    # ãƒ€ãƒŸãƒ¼ãƒ©ãƒ™ãƒ«ï¼ˆäºˆæ¸¬ã«ã¯ä½¿ç”¨ã•ã‚Œãªã„ï¼‰\n",
    "    dummy_labels = [0] * len(test_texts)\n",
    "    \n",
    "    # ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆä½œæˆ\n",
    "    print(\"ğŸ”§ ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆä½œæˆä¸­...\")\n",
    "    test_dataset = MathMisconceptionDataset(\n",
    "        test_texts, dummy_labels, tokenizer, max_length=512\n",
    "    )\n",
    "    \n",
    "    print(f\"âœ… ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ: {len(test_dataset)}ã‚µãƒ³ãƒ—ãƒ«\")\n",
    "    \n",
    "    # äºˆæ¸¬å®Ÿè¡Œ\n",
    "    print(\"ğŸ”® äºˆæ¸¬å®Ÿè¡Œä¸­...\")\n",
    "    try:\n",
    "        predictions = trainer.predict(test_dataset)\n",
    "        print(\"âœ… äºˆæ¸¬å®Œäº†!\")\n",
    "        \n",
    "        # ç¢ºç‡ã«å¤‰æ›\n",
    "        probs = torch.softmax(torch.tensor(predictions.predictions), dim=-1).numpy()\n",
    "        print(f\"ğŸ“Š äºˆæ¸¬å½¢çŠ¶: {probs.shape}\")\n",
    "        \n",
    "        # å„ã‚µãƒ³ãƒ—ãƒ«ã§ä¸Šä½3ã¤ã®äºˆæ¸¬ã‚’å–å¾—\n",
    "        print(\"ğŸ¯ TOP-3äºˆæ¸¬æŠ½å‡ºä¸­...\")\n",
    "        submission_predictions = []\n",
    "        \n",
    "        for i, prob in enumerate(probs):\n",
    "            # ç¢ºç‡ã®é«˜ã„é †ã«ä¸Šä½3ã¤ã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’å–å¾—\n",
    "            top3_indices = np.argsort(prob)[::-1][:3]\n",
    "            \n",
    "            # ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’å®Ÿéš›ã®ãƒ©ãƒ™ãƒ«åã«å¤‰æ›\n",
    "            top3_labels = [label_encoder.classes_[idx] for idx in top3_indices]\n",
    "            \n",
    "            # ã‚¹ãƒšãƒ¼ã‚¹åŒºåˆ‡ã‚Šã§çµåˆï¼ˆã‚³ãƒ³ãƒšè¦æ±‚å½¢å¼ï¼‰\n",
    "            prediction_string = \" \".join(top3_labels)\n",
    "            submission_predictions.append(prediction_string)\n",
    "            \n",
    "            # é€²æ—è¡¨ç¤ºï¼ˆæœ€åˆã®5ä»¶ï¼‰\n",
    "            if i < 5:\n",
    "                top3_probs = [prob[idx] for idx in top3_indices]\n",
    "                print(f\"  ã‚µãƒ³ãƒ—ãƒ« {i+1}: {prediction_string}\")\n",
    "                print(f\"    ç¢ºç‡: {[f'{p:.3f}' for p in top3_probs]}\")\n",
    "        \n",
    "        print(f\"âœ… TOP-3äºˆæ¸¬æŠ½å‡ºå®Œäº†: {len(submission_predictions)}ä»¶\")\n",
    "        \n",
    "        # äºˆæ¸¬ã®çµ±è¨ˆæƒ…å ±\n",
    "        all_predictions = \" \".join(submission_predictions).split()\n",
    "        from collections import Counter\n",
    "        pred_counts = Counter(all_predictions)\n",
    "        \n",
    "        print(f\"\\nğŸ“ˆ äºˆæ¸¬çµ±è¨ˆ:\")\n",
    "        print(f\"  äºˆæ¸¬ã«ä½¿ç”¨ã•ã‚ŒãŸã‚«ãƒ†ã‚´ãƒªæ•°: {len(pred_counts)}\")\n",
    "        for category, count in pred_counts.most_common():\n",
    "            percentage = count / (len(submission_predictions) * 3) * 100\n",
    "            print(f\"    {category}: {count}å› ({percentage:.1f}%)\")\n",
    "        \n",
    "        return submission_predictions\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ äºˆæ¸¬å®Ÿè¡Œä¸­ã«ã‚¨ãƒ©ãƒ¼: {e}\")\n",
    "        if torch.cuda.is_available():\n",
    "            print(f\"ğŸ–¥ï¸ ç¾åœ¨ã®GPUãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡: {torch.cuda.memory_allocated() / 1e6:.1f} MB\")\n",
    "        raise e\n",
    "\n",
    "# ãƒ†ã‚¹ãƒˆäºˆæ¸¬ã®å®Ÿè¡Œ\n",
    "if 'trainer' in locals() and 'label_encoder' in locals() and test_df is not None:\n",
    "    print(\"ğŸ”® ãƒ†ã‚¹ãƒˆã‚»ãƒƒãƒˆäºˆæ¸¬ã‚’é–‹å§‹ã—ã¾ã™...\")\n",
    "    test_predictions = generate_test_predictions(trainer, tokenizer, test_df, label_encoder)\n",
    "    print(\"ğŸ‰ ãƒ†ã‚¹ãƒˆäºˆæ¸¬å®Œäº†!\")\n",
    "else:\n",
    "    print(\"âŒ å¿…è¦ãªå¤‰æ•°ãŒæº–å‚™ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚å‰ã®ã‚»ãƒ«ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "435d0bc5",
   "metadata": {},
   "source": [
    "## ğŸ“¤ Create Submission File\n",
    "\n",
    "æœ€çµ‚ã‚¹ãƒ†ãƒƒãƒ—ã¨ã—ã¦ã€Kaggleã‚³ãƒ³ãƒšãƒ†ã‚£ã‚·ãƒ§ãƒ³ã«æå‡ºã™ã‚‹ãŸã‚ã®CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆã—ã¾ã™ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf432deb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_submission_file(test_df, predictions, output_path=\"submission.csv\"):\n",
    "    \"\"\"æå‡ºç”¨CSVãƒ•ã‚¡ã‚¤ãƒ«ã®ä½œæˆ\"\"\"\n",
    "    print(\"=\" * 60)\n",
    "    print(\"ğŸ“¤ æå‡ºãƒ•ã‚¡ã‚¤ãƒ«ä½œæˆ\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    if test_df is None or predictions is None:\n",
    "        print(\"âŒ ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã¾ãŸã¯äºˆæ¸¬çµæœãŒã‚ã‚Šã¾ã›ã‚“\")\n",
    "        return None\n",
    "    \n",
    "    print(f\"ğŸ“Š æå‡ºãƒ‡ãƒ¼ã‚¿: {len(predictions):,}ä»¶\")\n",
    "    \n",
    "    # æå‡ºç”¨ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ä½œæˆ\n",
    "    submission_df = pd.DataFrame({\n",
    "        'QuestionId_Answer': test_df.index,  # ã¾ãŸã¯test_df['QuestionId_Answer'] if available\n",
    "        'Correct': predictions\n",
    "    })\n",
    "    \n",
    "    print(f\"âœ… æå‡ºãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ä½œæˆå®Œäº†: {submission_df.shape}\")\n",
    "    print(f\"ğŸ“ åˆ—: {list(submission_df.columns)}\")\n",
    "    \n",
    "    # ã‚µãƒ³ãƒ—ãƒ«è¡¨ç¤º\n",
    "    print(f\"\\nğŸ“‹ æå‡ºãƒ‡ãƒ¼ã‚¿ã‚µãƒ³ãƒ—ãƒ«:\")\n",
    "    print(submission_df.head(10).to_string(index=False))\n",
    "    \n",
    "    # ãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜\n",
    "    try:\n",
    "        submission_df.to_csv(output_path, index=False)\n",
    "        print(f\"\\nğŸ’¾ æå‡ºãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜å®Œäº†: {output_path}\")\n",
    "        \n",
    "        # ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºç¢ºèª\n",
    "        import os\n",
    "        file_size = os.path.getsize(output_path)\n",
    "        print(f\"ğŸ“ ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º: {file_size:,} bytes ({file_size/1024:.1f} KB)\")\n",
    "        \n",
    "        # å½¢å¼ç¢ºèª\n",
    "        check_df = pd.read_csv(output_path)\n",
    "        print(f\"âœ… æå‡ºãƒ•ã‚¡ã‚¤ãƒ«æ¤œè¨¼: {check_df.shape}\")\n",
    "        print(f\"   å¿…è¦åˆ—å­˜åœ¨ç¢ºèª: {'QuestionId_Answer' in check_df.columns and 'Correct' in check_df.columns}\")\n",
    "        \n",
    "        # äºˆæ¸¬å½¢å¼ãƒã‚§ãƒƒã‚¯\n",
    "        sample_predictions = check_df['Correct'].head(5).tolist()\n",
    "        print(f\"ğŸ” äºˆæ¸¬å½¢å¼ã‚µãƒ³ãƒ—ãƒ«:\")\n",
    "        for i, pred in enumerate(sample_predictions):\n",
    "            pred_parts = pred.split()\n",
    "            print(f\"   {i+1}: {pred} (è¦ç´ æ•°: {len(pred_parts)})\")\n",
    "        \n",
    "        return submission_df\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ ãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜ã‚¨ãƒ©ãƒ¼: {e}\")\n",
    "        return None\n",
    "\n",
    "# æå‡ºãƒ•ã‚¡ã‚¤ãƒ«ã®ä½œæˆ\n",
    "if 'test_predictions' in locals() and test_df is not None:\n",
    "    print(\"ğŸ“¤ æå‡ºãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆã—ã¾ã™...\")\n",
    "    submission_df = create_submission_file(test_df, test_predictions, \"DeBERTa_v3_xsmall_submission.csv\")\n",
    "    \n",
    "    if submission_df is not None:\n",
    "        print(\"ğŸ‰ æå‡ºãƒ•ã‚¡ã‚¤ãƒ«ä½œæˆå®Œäº†!\")\n",
    "        print(f\"ğŸ“‹ æœ€çµ‚ç¢ºèª:\")\n",
    "        print(f\"   ãƒ•ã‚¡ã‚¤ãƒ«å: DeBERTa_v3_xsmall_submission.csv\")\n",
    "        print(f\"   ãƒ‡ãƒ¼ã‚¿ä»¶æ•°: {len(submission_df):,}\")\n",
    "        print(f\"   äºˆæ¸¬å½¢å¼: MAP@3 (å„è¡Œã«3ã¤ã®äºˆæ¸¬ã‚’ã‚¹ãƒšãƒ¼ã‚¹åŒºåˆ‡ã‚Š)\")\n",
    "        print(\"\\nğŸ† Kaggleã‚³ãƒ³ãƒšãƒ†ã‚£ã‚·ãƒ§ãƒ³ã«æå‡ºæº–å‚™å®Œäº†!\")\n",
    "    else:\n",
    "        print(\"âŒ æå‡ºãƒ•ã‚¡ã‚¤ãƒ«ä½œæˆã«å¤±æ•—ã—ã¾ã—ãŸ\")\n",
    "else:\n",
    "    print(\"âŒ å¿…è¦ãªãƒ‡ãƒ¼ã‚¿ãŒæº–å‚™ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚å‰ã®ã‚»ãƒ«ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb2cc21f",
   "metadata": {},
   "source": [
    "## ğŸ¯ Summary & Next Steps\n",
    "\n",
    "### ğŸ“Š å®Ÿè¡Œçµæœã‚µãƒãƒªãƒ¼\n",
    "ã“ã®ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯ã§ã¯ä»¥ä¸‹ã‚’å®Ÿè£…ã—ã¾ã—ãŸï¼š\n",
    "\n",
    "1. **ğŸ“š ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆæº–å‚™**: æ•°å­¦ã®èª¤è§£åˆ†é¡ãƒ‡ãƒ¼ã‚¿ã®å‰å‡¦ç†\n",
    "2. **ğŸ¤– ãƒ¢ãƒ‡ãƒ«è¨­å®š**: Microsoft DeBERTa-v3-xsmall (70M parameters)\n",
    "3. **âš¡ åŠ¹ç‡çš„ãªå­¦ç¿’**: Hugging Face Transformersã«ã‚ˆã‚‹æœ€é©åŒ–\n",
    "4. **ğŸ“ˆ è©•ä¾¡æŒ‡æ¨™**: MAP@3ã«ã‚ˆã‚‹æ€§èƒ½æ¸¬å®š\n",
    "5. **ğŸ”® ãƒ†ã‚¹ãƒˆäºˆæ¸¬**: TOP-3äºˆæ¸¬ã®ç”Ÿæˆ\n",
    "6. **ğŸ“¤ æå‡ºæº–å‚™**: Kaggleå½¢å¼ã®CSVãƒ•ã‚¡ã‚¤ãƒ«ä½œæˆ\n",
    "\n",
    "### ğŸ”§ ä½¿ç”¨æŠ€è¡“\n",
    "- **ãƒ¢ãƒ‡ãƒ«**: `microsoft/deberta-v3-xsmall`\n",
    "- **ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯**: PyTorch + Transformers\n",
    "- **è©•ä¾¡**: MAP@3 (Mean Average Precision at 3)\n",
    "- **æœ€é©åŒ–**: AdamW optimizer + Linear schedule\n",
    "\n",
    "### ğŸš€ æ”¹å–„ã®ã‚¢ã‚¤ãƒ‡ã‚¢\n",
    "- ãƒ‡ãƒ¼ã‚¿æ‹¡å¼µï¼ˆåŒç¾©èªç½®æ›ã€ãƒ‘ãƒ©ãƒ•ãƒ¬ãƒ¼ã‚ºï¼‰\n",
    "- ã‚ˆã‚Šå¤§ããªãƒ¢ãƒ‡ãƒ«ï¼ˆDeBERTa-large, RoBERTa-largeï¼‰\n",
    "- ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«æ‰‹æ³•ï¼ˆè¤‡æ•°ãƒ¢ãƒ‡ãƒ«ã®çµ„ã¿åˆã‚ã›ï¼‰\n",
    "- ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°\n",
    "- äº¤å·®æ¤œè¨¼ã«ã‚ˆã‚‹å®‰å®šæ€§å‘ä¸Š\n",
    "\n",
    "### ğŸ“ ä½¿ç”¨æ–¹æ³•\n",
    "1. å…¨ã‚»ãƒ«ã‚’é †ç•ªã«å®Ÿè¡Œ\n",
    "2. `DeBERTa_v3_xsmall_submission.csv`ãŒç”Ÿæˆã•ã‚Œã‚‹\n",
    "3. Kaggleã‚³ãƒ³ãƒšãƒ†ã‚£ã‚·ãƒ§ãƒ³ã«CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’æå‡º\n",
    "\n",
    "**ğŸ† Good luck with your competition!**"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
